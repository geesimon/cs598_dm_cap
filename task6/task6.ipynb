{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:\n",
    "* [NLTK](http://www.nltk.org/howto/classify.html)\n",
    "* [SpaCy](https://spacy.io/)\n",
    "* [AllenNLP](https://allennlp.org/tutorials)\n",
    "\n",
    "Articles:\n",
    "* [A Comprehensive Guide to Understand and Implement Text Classification in Python](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)\n",
    "* [Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "* [State-of-the-Art Text Classification using BERT model: “Predict the Happiness” Challenge](https://appliedmachinelearning.blog/2019/03/04/state-of-the-art-text-classification-using-bert-model-predict-the-happiness-hackerearth-challenge/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13299/13299 [03:43<00:00, 59.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    result_stemmed = []\n",
    "    for token in simple_preprocess(text, min_len = 2):\n",
    "        result.append(token)\n",
    "        if token not in STOPWORDS:\n",
    "            result_stemmed.append(lemmatize_stemming(token))\n",
    "    \n",
    "    return (result, result_stemmed)\n",
    "\n",
    "with open(\"./data/raw/Hygiene/hygiene.dat.labels\") as f:\n",
    "    LABELS = [int(l) for l in f.readlines() if l[0].isdigit()]\n",
    "\n",
    "ALL_RAW_TEXTS = []\n",
    "ALL_TEXTS = []\n",
    "ALL_STEMMED_TEXTS = []\n",
    "ALL_CONCAT_STEMMED_TEXTS = []\n",
    "LABELED_TEXTS = []\n",
    "LABELED_CONCAT_TEXTS = []\n",
    "LABELED_STEMMED_TEXTS = []\n",
    "LABELED_CONCAT_STEMMED_TEXTS = []\n",
    "\n",
    "with open(\"./data/raw/Hygiene/hygiene.dat\") as f:\n",
    "    ALL_RAW_TEXTS = f.readlines()\n",
    "\n",
    "for _text in tqdm(ALL_RAW_TEXTS):\n",
    "    _result, _result_stemmed = preprocess(_text)\n",
    "    ALL_TEXTS.append(_result)\n",
    "    ALL_STEMMED_TEXTS.append(_result_stemmed)\n",
    "\n",
    "ALL_CONCAT_STEMMED_TEXTS = [\" \".join(_text) for _text in ALL_STEMMED_TEXTS]\n",
    "\n",
    "LABELED_TEXTS = ALL_TEXTS[0:len(LABELS)]\n",
    "LABELED_CONCAT_TEXTS = [\" \".join(_text) for _text in LABELED_TEXTS]\n",
    "\n",
    "LABELED_STEMMED_TEXTS = ALL_STEMMED_TEXTS[0:len(LABELS)]\n",
    "LABELED_CONCAT_STEMMED_TEXTS = [\" \".join(_text) for _text in LABELED_STEMMED_TEXTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handle Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_map = 'abcdefghij'\n",
    "# code_map = '0123456789'\n",
    "\n",
    "def encode_zipcode(zip_code):\n",
    "    _code = ''\n",
    "    _rest = zip_code    \n",
    "    while _rest > 0:\n",
    "        _code = code_map[_rest % 10] + _code\n",
    "        _rest = int(_rest / 10)\n",
    "\n",
    "    return _code\n",
    "\n",
    "FEATURE_MORE =pd.read_csv(\"./data/raw/Hygiene/hygiene.dat.additional\", header=None)\n",
    "EXTRA_FEATURE = pd.DataFrame()\n",
    "\n",
    "EXTRA_FEATURE['Cuisines'] = [simple_preprocess(_text) for _text in FEATURE_MORE[0]]\n",
    "\n",
    "EXTRA_FEATURE['Stars'] = ['PoorStars' for _star in FEATURE_MORE[3]]\n",
    "star_std_range = (FEATURE_MORE[3].mean() - FEATURE_MORE[3].std(), FEATURE_MORE[3].mean() + FEATURE_MORE[3].std())\n",
    "# EXTRA_FEATURE['Stars'][FEATURE_MORE[3] < star_std_range[0]] = 'PoorStars'\n",
    "EXTRA_FEATURE['Stars'][(FEATURE_MORE[3] >= star_std_range[0])] = 'StandardStars'\n",
    "EXTRA_FEATURE['Stars'][FEATURE_MORE[3] > star_std_range[1]] = 'GoodStars'\n",
    "\n",
    "EXTRA_FEATURE['ReviewCount'] = ['NoReviews' for _star in FEATURE_MORE[2]]\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 2] = \"FewReviews\"\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 6] = \"SomeReviews\"\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 13] = \"ManyReviews\"\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 50] = \"LotReviews\"\n",
    "\n",
    "EXTRA_FEATURE['ZIPCode'] = [encode_zipcode(_code) for _code in FEATURE_MORE[1]]\n",
    "\n",
    "EXTRA_FEATURE['MergedText'] = [ [_cuisine for _cuisine in _record[1][0]]\n",
    "                                + [_record[1][1]] + [_record[1][2]] + [_record[1][3]]\n",
    "                               for _record in EXTRA_FEATURE.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Extra Features to the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_FEATURES = EXTRA_FEATURE['MergedText'][0:len(LABELS)]\n",
    "EXTRA_CONCAT_FEATURES = [\" \".join(_text) for _text in EXTRA_FEATURES]\n",
    "                  \n",
    "LABELED_EXTRA_TEXTS =  [EXTRA_FEATURES[i] + _text for i, _text in enumerate(LABELED_TEXTS)]\n",
    "LABELED_EXTRA_CONCAT_TEXTS = [\" \".join(_text) for _text in LABELED_EXTRA_TEXTS]\n",
    "\n",
    "LABELED_EXTRA_STEMMED_TEXTS = [LABELED_EXTRA_TEXTS[i] + _text for i, _text in enumerate(LABELED_STEMMED_TEXTS)]\n",
    "LABELED_EXTRA_CONCAT_STEMMED_TEXTS = [\" \".join(_text) for _text in LABELED_EXTRA_STEMMED_TEXTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABLED_RAW_TEXTS_1 = [EXTRA_CONCAT_FEATURES[i] + \"|\" + _text for i, _text in enumerate(ALL_RAW_TEXTS[0:len(LABELS)]) if LABELS[i] == 1]\n",
    "LABLED_RAW_TEXTS_0 = [EXTRA_CONCAT_FEATURES[i] + \"|\" + _text for i, _text in enumerate(ALL_RAW_TEXTS[0:len(LABELS)]) if LABELS[i] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 52\n"
     ]
    }
   ],
   "source": [
    "SMALL_RAW_TEXTS_1 = [_text for _text in LABLED_RAW_TEXTS_1 if len(_text) < 1000]\n",
    "SMALL_RAW_TEXTS_0 = [_text for _text in LABLED_RAW_TEXTS_0 if len(_text) < 1000]\n",
    "print(len(SMALL_RAW_TEXTS_1), len(SMALL_RAW_TEXTS_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"breakfast brunch greek restaurants StandardStars NoReviews jibjj|Tickled to find a good breakfast in Magnolia - because there aren't any others. Great home cooking - thin potatoes and two great eggs. Coffee, orange juice and the Greek language.Perfect early morning.\\n\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMALL_RAW_TEXTS_1[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pizza restaurants GoodStars NoReviews jibaj|Pizza Hut Internet Delivery is uncomplicated. They take cash and credit orders. Gave me an estimated time of delivery. And emailed the receipt. Really simple.A timely delivery in rain was enough to impress me. But the delivery woman was smiling and courteous. She gave me parmesan and pepper packets. Thanks.Pizza Hut couldn't stop there.... The Veggie-Lovers Pizza came piping hot. It was adorned by tons of fresh chopped veggies like more than I expected. So much so that the sauce couldn't even peek. Fer real.And today is Pizza Hut's Wing Wednesday. Thus decided to add some boneless wings with ranch dressing to my pizza order. Too much food. But it'll make enjoyable leftovers. Also they gave me a free liter of the new Pepsi Max on top of their newly lowered pizza prices. Sinful spinster.... I am!\\n\""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMALL_RAW_TEXTS_0[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using texts and lables\n",
    "labeled_df = pd.DataFrame()\n",
    "labeled_df['concat_stemmed_text'] = LABELED_CONCAT_STEMMED_TEXTS\n",
    "labeled_df['stemmed_text'] = LABELED_STEMMED_TEXTS\n",
    "# labeled_df['concat_stemmed_text'] = LABELED_CONCAT_TEXTS\n",
    "# labeled_df['stemmed_text'] = LABELED_TEXTS\n",
    "# labeled_df['concat_stemmed_text'] = LABELED_CONCAT_EXTRA_TEXTS\n",
    "# labeled_df['stemmed_text'] = LABELED_EXTRA_TEXTS\n",
    "labeled_df['label'] = LABELS\n",
    "\n",
    "# split the dataset into training and validation datasets \n",
    "train_concat_stemmed_text, test_concat_stemmed_text, train_label, test_label = model_selection.train_test_split(labeled_df['concat_stemmed_text'], \n",
    "                                                                                  labeled_df['label'],\n",
    "                                                                                  test_size = 0.2,\n",
    "                                                                                  random_state = 10)\n",
    "train_stemmed_text = labeled_df['stemmed_text'][train_concat_stemmed_text.index]\n",
    "test_stemmed_text = labeled_df['stemmed_text'][test_concat_stemmed_text.index]\n",
    "\n",
    "# # label encode the target variable \n",
    "# encoder = preprocessing.LabelEncoder()\n",
    "# train_label = encoder.fit_transform(train_label)\n",
    "# test_label = encoder.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = corpora.Dictionary(processed_docs)\n",
    "# print(\"Before prunn:%d\"%(len(dictionary)))\n",
    "# dictionary.filter_extremes(no_below = 2, no_above = 0.5)\n",
    "# print(\"After prunn:%d\"%(len(dictionary)))\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCountVectorizer:\n",
    "    def __init__(self, max_df = 0.5):\n",
    "        self.vect_model = CountVectorizer(analyzer='word', max_df = max_df)\n",
    "        \n",
    "    def fit(self, texts_concat):\n",
    "        self.vect_model.fit(texts_concat)\n",
    "    \n",
    "    def transform(self, texts_concat):\n",
    "        return self.vect_model.transform(texts_concat)\n",
    "\n",
    "count_vect = MyCountVectorizer()\n",
    "count_vect.fit(train_concat_stemmed_text)\n",
    "train_count = count_vect.transform(train_concat_stemmed_text)\n",
    "test_count =  count_vect.transform(test_concat_stemmed_text)\n",
    "labeled_count = count_vect.transform(LABELED_CONCAT_STEMMED_TEXTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 363 ms, total: 11.9 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# word level tf-idf\n",
    "class MyTfidfVectorizer(MyCountVectorizer):\n",
    "    def __init__(self, analyzer='word', ngram_range = None, max_features=5000):\n",
    "        if ngram_range is None:\n",
    "            self.vect_model = TfidfVectorizer(analyzer = analyzer, max_features = max_features)\n",
    "        else:\n",
    "            self.vect_model = TfidfVectorizer(analyzer = analyzer, ngram_range = ngram_range, \n",
    "                                              max_features = max_features)\n",
    "            \n",
    "    def fit(self, texts_concat):   \n",
    "        self.vect_model.fit(texts_concat)\n",
    "        self.vocabulary = self.vect_model.vocabulary_\n",
    "\n",
    "\n",
    "tfidf_vect = MyTfidfVectorizer(max_features = 10000)\n",
    "tfidf_vect.fit(train_concat_stemmed_text)\n",
    "train_tfidf =  tfidf_vect.transform(train_concat_stemmed_text)\n",
    "test_tfidf =  tfidf_vect.transform(test_concat_stemmed_text)\n",
    "labeled_tfidf =  tfidf_vect.transform(LABELED_CONCAT_STEMMED_TEXTS)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = MyTfidfVectorizer(ngram_range=(2,3), max_features = 10000)\n",
    "tfidf_vect_ngram.fit(train_concat_stemmed_text)\n",
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(train_concat_stemmed_text)\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(test_concat_stemmed_text)\n",
    "labeled_tfidf_ngram = tfidf_vect_ngram.transform(LABELED_CONCAT_STEMMED_TEXTS)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = MyTfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features = 10000)\n",
    "tfidf_vect_ngram_chars.fit(train_concat_stemmed_text)\n",
    "train_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_concat_stemmed_text) \n",
    "test_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_concat_stemmed_text)\n",
    "labeled_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(LABELED_CONCAT_STEMMED_TEXTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build from review corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from gensim.models.fasttext import FastText\n",
    "\n",
    "# class MyFastTextTfidfVectorizer(MyCountVectorizer):\n",
    "#     def __init__(self, tfidf_vectorizer, size = 100):\n",
    "#         self.embedding_size = size\n",
    "#         self.tfidf_vectorizer = tfidf_vectorizer\n",
    "#         self.fasttext_model = FastText(size = size, window = 5, min_count = 5)\n",
    "\n",
    "#     def tfidf2embedding(self, value_vector):\n",
    "#         _weighted_value = np.zeros(self.embedding_size)\n",
    "#         for key in self.tfidf_vectorizer.vocabulary:\n",
    "#             _index = self.tfidf_vectorizer.vocabulary[key]\n",
    "#             if value_vector[_index] != 0:\n",
    "#                 _weighted_value += self.fasttext_model[key] * value_vector[_index]\n",
    "\n",
    "#         return _weighted_value\n",
    "    \n",
    "#     def fit(self, texts):\n",
    "#         _texts_concat = [\" \".join(_text) for _text in texts]\n",
    "#         self.tfidf_vectorizer = MyTfidfVectorizer()\n",
    "#         self.tfidf_vectorizer.fit(_texts_concat)\n",
    "        \n",
    "#         self.fasttext_model.build_vocab(sentences = texts)\n",
    "#         self.fasttext_model.train(sentences = texts, \n",
    "#                                   total_examples = len(texts), \n",
    "#                                   epochs=10)\n",
    "        \n",
    "#     def transform(self, texts):\n",
    "#         _texts_concat = [\" \".join(_text) for _text in texts]\n",
    "#         _tfidf_values = self.tfidf_vectorizer.transform(_texts_concat)\n",
    "#         return np.asarray([self.tfidf2embedding(_value.toarray()[0]) for _value in _tfidf_values])\n",
    "\n",
    "# fasttext_tfidf_vect = MyFastTextTfidfVectorizer(tfidf_vect)\n",
    "# fasttext_tfidf_vect.fit(ALL_STEMMED_TEXTS)\n",
    "# train_fasttext_embedding = fasttext_tfidf_vect.transform(train_stemmed_text)\n",
    "# test_fasttext_embedding = fasttext_tfidf_vect.transform(test_stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prebuilt Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from keras.preprocessing import text, sequence\n",
    "# from keras import layers, models, optimizers\n",
    "\n",
    "# # load the pre-trained word-embedding vectors \n",
    "# embeddings_index = {}\n",
    "# for i, line in enumerate(open('data/model/wiki-news-300d-1M.vec')):\n",
    "#     values = line.split()\n",
    "#     embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# # create a tokenizer \n",
    "# token = text.Tokenizer()\n",
    "# token.fit_on_texts(LABELED_CONCAT_STEMMED_TEXTS)\n",
    "# word_index = token.word_index\n",
    "\n",
    "# # convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "# text_train_seq = sequence.pad_sequences(token.texts_to_sequences(train_text), maxlen=70)\n",
    "# text_test_seq = sequence.pad_sequences(token.texts_to_sequences(test_text), maxlen=70)\n",
    "\n",
    "# # create token-embedding mapping\n",
    "# embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "# for word, i in word_index.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text / NLP based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "# trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "# trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "# trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "# trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "# trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import textblob\n",
    "\n",
    "# pos_family = {\n",
    "#     'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "#     'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "#     'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "#     'adj' :  ['JJ','JJR','JJS'],\n",
    "#     'adv' : ['RB','RBR','RBS','WRB']\n",
    "# }\n",
    "\n",
    "# # function to check and get the part of speech tag count of a words in a given sentence\n",
    "# def check_pos_tag(x, flag):\n",
    "#     cnt = 0\n",
    "#     try:\n",
    "#         wiki = textblob.TextBlob(x)\n",
    "#         for tup in wiki.tags:\n",
    "#             ppo = list(tup)[1]\n",
    "#             if ppo in pos_family[flag]:\n",
    "#                 cnt += 1\n",
    "#     except:\n",
    "#         pass\n",
    "#     return cnt\n",
    "\n",
    "# trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "# trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "# trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "# trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "# trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a LDA Model\n",
    "# lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "# X_topics = lda_model.fit_transform(text_train_count)\n",
    "# topic_word = lda_model.components_\n",
    "# vocab = count_vect.get_feature_names()\n",
    "\n",
    "# # view the topic models\n",
    "# n_top_words = 10\n",
    "# topic_summaries = []\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "#     topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.12 s, sys: 248 ms, total: 5.37 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "from gensim import corpora, models\n",
    "\n",
    "class MyLDAVectorizer(MyCountVectorizer):\n",
    "    mallet_path = \"..\" + os.sep + \"mallet-2.0.8\"+ os.sep + \"bin\" + os.sep +\"mallet\"\n",
    "    \n",
    "    def __init__(self, TOPIC_COUNT = 100):\n",
    "        self.topic_count = TOPIC_COUNT\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        self.dictionary = corpora.Dictionary(texts)\n",
    "        _corpus = [self.dictionary.doc2bow(_doc) for _doc in texts]\n",
    "        self.tfidf_model = models.TfidfModel(_corpus)\n",
    "        _tfidf_corpus = self.tfidf_model[_corpus]\n",
    "\n",
    "#         self.vect_model = models.LdaModel(_tfidf_corpus, \n",
    "#                             num_topics = self.topic_count, \n",
    "#                             id2word = self.dictionary,\n",
    "#                             random_state = 100,\n",
    "#                             eval_every = 5, \n",
    "#                             alpha = 'auto', \n",
    "#                             gamma_threshold = 0.01)\n",
    "        \n",
    "        self.vect_model = models.wrappers.LdaMallet(self.mallet_path, \n",
    "                                                     corpus = _corpus, \n",
    "                                                     num_topics = self.topic_count, \n",
    "                                                     id2word = self.dictionary)\n",
    "    \n",
    "    def toarray(self, doc_topics):\n",
    "        _doc_vect  = np.zeros((len(doc_topics), self.topic_count))\n",
    "        \n",
    "        for i, _doc in enumerate(doc_topics):\n",
    "            for _topic, _weight in _doc:\n",
    "                _doc_vect[i][_topic] = _weight\n",
    "        \n",
    "        return _doc_vect\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        _corpus = [self.dictionary.doc2bow(_doc) for _doc in texts]\n",
    "#         _tfidf_corpus = self.tfidf_model[_corpus]\n",
    "        \n",
    "        return self.toarray(self.vect_model[_corpus])\n",
    "\n",
    "lda_vect = MyLDAVectorizer(TOPIC_COUNT = 200)\n",
    "# lda_vect.fit(train_stemmed_text)\n",
    "lda_vect.fit(LABELED_STEMMED_TEXTS)\n",
    "train_lda = lda_vect.transform(train_stemmed_text)\n",
    "test_lda = lda_vect.transform(test_stemmed_text)\n",
    "labeled_lda = lda_vect.transform(LABELED_STEMMED_TEXTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 56s, sys: 13 s, total: 13min 9s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import numpy as np\n",
    "\n",
    "class MyDoc2Vectorizer(MyCountVectorizer):\n",
    "    def __init__(self, size = 100):\n",
    "        self.embedding_size = size\n",
    "            \n",
    "    def fit(self, texts):\n",
    "        _docs = [TaggedDocument(_doc, [i]) for i, _doc in enumerate(texts)]\n",
    "        self.vect_model = Doc2Vec(_docs, \n",
    "                                  vector_size = self.embedding_size, \n",
    "                                  window = 5,\n",
    "                                  min_count = 3,\n",
    "                                  epochs = 40, \n",
    "                                  workers = 4)\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        return np.asarray([self.vect_model.infer_vector(_text) for _text in texts])\n",
    "\n",
    "doc2vec_vect = MyDoc2Vectorizer(size = 200)\n",
    "doc2vec_vect.fit(ALL_STEMMED_TEXTS)\n",
    "# doc2vec_vect.fit(train_stemmed_text)\n",
    "train_doc2vec = doc2vec_vect.transform(train_stemmed_text)\n",
    "test_doc2vec = doc2vec_vect.transform(test_stemmed_text)\n",
    "labeled_doc2vec = doc2vec_vect.transform(LABELED_STEMMED_TEXTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({11124: 1,\n",
       "         4881: 1,\n",
       "         1088: 1,\n",
       "         148: 1,\n",
       "         9327: 2,\n",
       "         6146: 1,\n",
       "         8749: 1,\n",
       "         6669: 1,\n",
       "         2652: 1,\n",
       "         9791: 1,\n",
       "         3642: 1,\n",
       "         4: 1,\n",
       "         4776: 1,\n",
       "         7402: 1,\n",
       "         5411: 1,\n",
       "         1459: 1,\n",
       "         365: 1,\n",
       "         1644: 1,\n",
       "         12044: 1,\n",
       "         2114: 1,\n",
       "         1659: 1,\n",
       "         6573: 1,\n",
       "         9973: 1,\n",
       "         4712: 1,\n",
       "         3544: 1,\n",
       "         9937: 1,\n",
       "         3309: 1,\n",
       "         582: 1,\n",
       "         12344: 1,\n",
       "         2415: 1,\n",
       "         5072: 1,\n",
       "         10201: 1,\n",
       "         12453: 1,\n",
       "         11078: 1,\n",
       "         2443: 1,\n",
       "         2437: 1,\n",
       "         5774: 1,\n",
       "         7933: 1,\n",
       "         8992: 1,\n",
       "         5881: 1,\n",
       "         9991: 1,\n",
       "         6932: 1,\n",
       "         512: 1,\n",
       "         3565: 1,\n",
       "         11639: 2,\n",
       "         8464: 1,\n",
       "         12944: 1,\n",
       "         5665: 1,\n",
       "         13047: 1,\n",
       "         5513: 1,\n",
       "         10848: 1,\n",
       "         5787: 1,\n",
       "         724: 1,\n",
       "         12663: 1,\n",
       "         11409: 1,\n",
       "         8084: 1,\n",
       "         6106: 1,\n",
       "         7513: 1,\n",
       "         3818: 1,\n",
       "         6752: 1,\n",
       "         4733: 1,\n",
       "         5487: 1,\n",
       "         1872: 1,\n",
       "         12632: 1,\n",
       "         12216: 1,\n",
       "         5633: 1,\n",
       "         5717: 1,\n",
       "         5095: 1,\n",
       "         12257: 1,\n",
       "         9004: 1,\n",
       "         2881: 1,\n",
       "         2330: 1,\n",
       "         4167: 1,\n",
       "         1219: 1,\n",
       "         11726: 1,\n",
       "         9910: 1,\n",
       "         10516: 1,\n",
       "         12828: 1,\n",
       "         617: 1,\n",
       "         9625: 1,\n",
       "         1774: 1,\n",
       "         5066: 2,\n",
       "         8889: 1,\n",
       "         2210: 1,\n",
       "         6670: 1,\n",
       "         11945: 1,\n",
       "         8717: 1,\n",
       "         11735: 1,\n",
       "         478: 1,\n",
       "         6156: 1,\n",
       "         2243: 1,\n",
       "         9989: 1,\n",
       "         8120: 1,\n",
       "         3693: 1,\n",
       "         11358: 1,\n",
       "         11387: 1,\n",
       "         6141: 1,\n",
       "         12107: 1,\n",
       "         9611: 1,\n",
       "         210: 1,\n",
       "         2555: 1,\n",
       "         146: 1,\n",
       "         13091: 1,\n",
       "         11570: 1,\n",
       "         6836: 1,\n",
       "         5281: 1,\n",
       "         2731: 1,\n",
       "         10465: 1,\n",
       "         10876: 1,\n",
       "         1095: 1,\n",
       "         2878: 2,\n",
       "         4775: 2,\n",
       "         5111: 1,\n",
       "         8685: 1,\n",
       "         4952: 1,\n",
       "         4232: 1,\n",
       "         5688: 1,\n",
       "         5492: 1,\n",
       "         7569: 2,\n",
       "         8450: 1,\n",
       "         9384: 1,\n",
       "         1722: 1,\n",
       "         6257: 1,\n",
       "         7711: 1,\n",
       "         2550: 1,\n",
       "         2205: 1,\n",
       "         2800: 1,\n",
       "         3158: 1,\n",
       "         8092: 1,\n",
       "         579: 1,\n",
       "         9732: 1,\n",
       "         12160: 1,\n",
       "         4288: 1,\n",
       "         1230: 1,\n",
       "         943: 1,\n",
       "         1845: 1,\n",
       "         11634: 1,\n",
       "         3542: 1,\n",
       "         6738: 1,\n",
       "         3646: 1,\n",
       "         2683: 1,\n",
       "         6554: 1,\n",
       "         13225: 1,\n",
       "         5695: 1,\n",
       "         672: 1,\n",
       "         9362: 1,\n",
       "         5257: 1,\n",
       "         6757: 1,\n",
       "         8272: 1,\n",
       "         12472: 1,\n",
       "         9381: 1,\n",
       "         11276: 1,\n",
       "         11910: 1,\n",
       "         10412: 1,\n",
       "         7578: 1,\n",
       "         4003: 1,\n",
       "         2417: 1,\n",
       "         1439: 1,\n",
       "         3306: 1,\n",
       "         7424: 1,\n",
       "         2911: 1,\n",
       "         10705: 1,\n",
       "         2588: 1,\n",
       "         7069: 1,\n",
       "         4039: 1,\n",
       "         12524: 1,\n",
       "         8600: 1,\n",
       "         9518: 1,\n",
       "         5109: 1,\n",
       "         4259: 1,\n",
       "         6350: 1,\n",
       "         4966: 1,\n",
       "         6443: 1,\n",
       "         6492: 1,\n",
       "         4625: 1,\n",
       "         7175: 1,\n",
       "         3785: 1,\n",
       "         1150: 1,\n",
       "         7524: 1,\n",
       "         5981: 1,\n",
       "         3409: 1,\n",
       "         8257: 1,\n",
       "         5674: 1,\n",
       "         10598: 1,\n",
       "         12513: 1,\n",
       "         8058: 1,\n",
       "         6581: 1,\n",
       "         13167: 1,\n",
       "         9714: 1,\n",
       "         10522: 1,\n",
       "         8358: 1,\n",
       "         1519: 1,\n",
       "         4545: 1,\n",
       "         12798: 1,\n",
       "         10450: 1,\n",
       "         2736: 1,\n",
       "         1931: 1,\n",
       "         3331: 1,\n",
       "         6814: 1,\n",
       "         7919: 1,\n",
       "         4860: 1,\n",
       "         10914: 1,\n",
       "         10781: 1,\n",
       "         7867: 1,\n",
       "         10454: 1,\n",
       "         12767: 1,\n",
       "         11760: 1,\n",
       "         11010: 1,\n",
       "         6776: 1,\n",
       "         349: 1,\n",
       "         12526: 1,\n",
       "         11518: 1,\n",
       "         3650: 1,\n",
       "         12391: 1,\n",
       "         1156: 1,\n",
       "         10534: 1,\n",
       "         3212: 1,\n",
       "         2039: 1,\n",
       "         7006: 1,\n",
       "         1472: 1,\n",
       "         1971: 1,\n",
       "         6238: 1,\n",
       "         12585: 1,\n",
       "         9488: 1,\n",
       "         7138: 1,\n",
       "         5057: 1,\n",
       "         4002: 1,\n",
       "         10677: 1,\n",
       "         5840: 1,\n",
       "         12512: 1,\n",
       "         10806: 1,\n",
       "         2017: 1,\n",
       "         9071: 1,\n",
       "         9630: 1,\n",
       "         8142: 1,\n",
       "         9903: 1,\n",
       "         10646: 1,\n",
       "         13234: 1,\n",
       "         4754: 1,\n",
       "         12373: 1,\n",
       "         4777: 1,\n",
       "         10898: 1,\n",
       "         12696: 1,\n",
       "         7189: 1,\n",
       "         5102: 1,\n",
       "         9972: 1,\n",
       "         10788: 1,\n",
       "         10365: 1,\n",
       "         12343: 1,\n",
       "         6912: 1,\n",
       "         6406: 1,\n",
       "         11600: 1,\n",
       "         9256: 1,\n",
       "         3361: 1,\n",
       "         4973: 1,\n",
       "         10212: 1,\n",
       "         10651: 1,\n",
       "         1636: 1,\n",
       "         2974: 1,\n",
       "         7871: 1,\n",
       "         2089: 1,\n",
       "         9615: 1,\n",
       "         2671: 1,\n",
       "         10326: 1,\n",
       "         136: 1,\n",
       "         4530: 1,\n",
       "         12727: 1,\n",
       "         593: 1,\n",
       "         1908: 1,\n",
       "         7959: 1,\n",
       "         7851: 1,\n",
       "         12428: 1,\n",
       "         11737: 1,\n",
       "         3465: 1,\n",
       "         11756: 1,\n",
       "         9514: 1,\n",
       "         3526: 1,\n",
       "         4898: 1,\n",
       "         7288: 1,\n",
       "         9078: 1,\n",
       "         5311: 1,\n",
       "         7840: 1,\n",
       "         9997: 1,\n",
       "         8498: 1,\n",
       "         4133: 1,\n",
       "         5307: 1,\n",
       "         12352: 1,\n",
       "         3846: 1,\n",
       "         11665: 1,\n",
       "         10622: 1,\n",
       "         3115: 1,\n",
       "         9447: 1,\n",
       "         8961: 1,\n",
       "         1297: 1,\n",
       "         8055: 1,\n",
       "         1875: 1,\n",
       "         8038: 1,\n",
       "         3606: 1,\n",
       "         7935: 1,\n",
       "         7002: 1,\n",
       "         7864: 1,\n",
       "         2586: 1,\n",
       "         9475: 1,\n",
       "         7295: 1,\n",
       "         12665: 1,\n",
       "         6042: 1,\n",
       "         1585: 1,\n",
       "         6162: 1,\n",
       "         8691: 1,\n",
       "         4084: 1,\n",
       "         8256: 1,\n",
       "         12860: 1,\n",
       "         12783: 1,\n",
       "         7846: 1,\n",
       "         9521: 1,\n",
       "         676: 1,\n",
       "         9471: 1,\n",
       "         4413: 1,\n",
       "         6775: 1,\n",
       "         7883: 1,\n",
       "         12862: 1,\n",
       "         1746: 1,\n",
       "         5009: 1,\n",
       "         337: 1,\n",
       "         3709: 1,\n",
       "         3797: 1,\n",
       "         11563: 1,\n",
       "         12071: 1,\n",
       "         7462: 1,\n",
       "         8117: 1,\n",
       "         10826: 1,\n",
       "         8995: 1,\n",
       "         8604: 1,\n",
       "         8324: 1,\n",
       "         1204: 1,\n",
       "         5304: 1,\n",
       "         10553: 1,\n",
       "         3099: 1,\n",
       "         6217: 1,\n",
       "         13272: 1,\n",
       "         9076: 1,\n",
       "         613: 1,\n",
       "         12149: 1,\n",
       "         8410: 1,\n",
       "         12174: 1,\n",
       "         11578: 1,\n",
       "         5903: 1,\n",
       "         174: 1,\n",
       "         8769: 1,\n",
       "         4075: 1,\n",
       "         2722: 1,\n",
       "         7528: 1,\n",
       "         10678: 1,\n",
       "         10369: 1,\n",
       "         3754: 1,\n",
       "         8926: 1,\n",
       "         8011: 1,\n",
       "         2409: 1,\n",
       "         8421: 1,\n",
       "         7939: 1,\n",
       "         10480: 1,\n",
       "         12600: 1,\n",
       "         2448: 1,\n",
       "         5990: 1,\n",
       "         12396: 1,\n",
       "         9194: 1,\n",
       "         8158: 1,\n",
       "         1967: 1,\n",
       "         11403: 1,\n",
       "         2122: 1,\n",
       "         171: 1,\n",
       "         13121: 1,\n",
       "         11877: 1,\n",
       "         5822: 1,\n",
       "         1858: 1,\n",
       "         12023: 1,\n",
       "         11169: 1,\n",
       "         4499: 1,\n",
       "         12317: 1,\n",
       "         3207: 1,\n",
       "         10507: 1,\n",
       "         2190: 1,\n",
       "         9562: 1,\n",
       "         11734: 1,\n",
       "         2750: 1,\n",
       "         8694: 1,\n",
       "         4178: 1,\n",
       "         9290: 1,\n",
       "         327: 1,\n",
       "         2251: 1,\n",
       "         2773: 1,\n",
       "         4518: 1,\n",
       "         7078: 1,\n",
       "         12133: 1,\n",
       "         1118: 1,\n",
       "         9880: 1,\n",
       "         443: 1,\n",
       "         3610: 1,\n",
       "         3914: 1,\n",
       "         8972: 1,\n",
       "         1330: 1,\n",
       "         5121: 1,\n",
       "         5100: 1,\n",
       "         12218: 1,\n",
       "         523: 1,\n",
       "         12970: 1,\n",
       "         10484: 1,\n",
       "         6277: 1,\n",
       "         11870: 1,\n",
       "         10139: 1,\n",
       "         726: 1,\n",
       "         9529: 1,\n",
       "         2162: 1,\n",
       "         5229: 1,\n",
       "         4096: 1,\n",
       "         1965: 1,\n",
       "         1206: 1,\n",
       "         4175: 1,\n",
       "         12599: 1,\n",
       "         5115: 1,\n",
       "         332: 1,\n",
       "         11499: 1,\n",
       "         12722: 1,\n",
       "         1532: 1,\n",
       "         7927: 1,\n",
       "         6242: 1,\n",
       "         3336: 1,\n",
       "         6586: 1,\n",
       "         1256: 1,\n",
       "         1359: 1})"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test quality\n",
    "\n",
    "import collections\n",
    "\n",
    "ranks = []\n",
    "for doc_id in range(len(train_stemmed_text)):\n",
    "    inferred_vector = doc2vec_vect.vect_model.infer_vector(train_stemmed_text[train_stemmed_text.index[doc_id]])\n",
    "    sims = doc2vec_vect.vect_model.docvecs.most_similar([inferred_vector], topn=len(doc2vec_vect.vect_model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "collections.Counter(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def show_score(classifier_name, scores):\n",
    "    print(\"Accuracy:%0.2f Precission:%0.2f Recall:%0.2f F1:%0.2f\"%scores, \"-> [%s]\"%(classifier_name))\n",
    "    \n",
    "def train_model(classifier, train_feature, train_label, test_feature, test_label, is_neural_net=False):\n",
    "#     print(train_feature)\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(train_feature, train_label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(test_feature)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    print(metrics.confusion_matrix(test_label, predictions))\n",
    "    return (metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))\n",
    "\n",
    "def run_model(classfier_configs):\n",
    "    for _name in classfier_configs:\n",
    "#         print(classfier_configs[_name].train)\n",
    "        scores = train_model(classfier_configs[_name][0], classfier_configs[_name][1], train_label, classfier_configs[_name][2], test_label)\n",
    "        show_score(_name, scores)\n",
    "\n",
    "def eval_model(classfier_configs):\n",
    "    for _name in classfier_configs:\n",
    "        cv_results = cross_validate(classfier_configs[_name][0], \n",
    "                                    classfier_configs[_name][1], \n",
    "                                    classfier_configs[_name][2],\n",
    "                                    scoring = 'f1',\n",
    "                                    cv = 5)\n",
    "        print(cv_results['test_score'], np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57943925 0.72881356 0.7008547  0.67241379 0.60550459] 0.657405178554519\n",
      "[0.62295082 0.69767442 0.7        0.71014493 0.67768595] 0.6816912232452474\n",
      "[0.56637168 0.74576271 0.70588235 0.63716814 0.59615385] 0.6502677467936558\n",
      "[0.63157895 0.67515924 0.66666667 0.65789474 0.63945578] 0.6541510737717816\n",
      "[0.61111111 0.67924528 0.68376068 0.64220183 0.55102041] 0.6334678641832626\n"
     ]
    }
   ],
   "source": [
    "# nb_config = {\n",
    "#     \"NB Count\": (naive_bayes.MultinomialNB(), train_count, test_count),\n",
    "#     \"NB TFIDF\": (naive_bayes.MultinomialNB(), train_tfidf, test_tfidf),\n",
    "#     \"NB TFIDF NGram\": (naive_bayes.MultinomialNB(), train_tfidf_ngram, test_tfidf_ngram),\n",
    "#     \"NB TFIDF NGram Chars\": (naive_bayes.MultinomialNB(), train_tfidf_ngram_chars, test_tfidf_ngram_chars),\n",
    "#     \"NB LDA\": (naive_bayes.MultinomialNB(), train_lda, test_lda),\n",
    "# }\n",
    "\n",
    "# run_model(nb_config)\n",
    "\n",
    "nb_config = {\n",
    "    \"NB Count\": (naive_bayes.MultinomialNB(), labeled_count, LABELS)\n",
    "    , \"NB TFIDF\": (naive_bayes.MultinomialNB(), labeled_tfidf, LABELS)\n",
    "    , \"NB TFIDF NGram\": (naive_bayes.MultinomialNB(), labeled_tfidf_ngram, LABELS)\n",
    "    , \"NB TFIDF NGram Chars\": (naive_bayes.MultinomialNB(), labeled_tfidf_ngram_chars, LABELS)\n",
    "    , \"NB LDA\": (naive_bayes.MultinomialNB(), labeled_lda, LABELS)\n",
    "}\n",
    "\n",
    "eval_model(nb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model = naive_bayes.MultinomialNB()\n",
    "# nb_model.fit(train_tfidf, train_label)\n",
    "# predictions = nb_model.predict(test_tfidf)     \n",
    "# predictions_probs = nb_model.predict_proba(test_tfidf)\n",
    "\n",
    "# new_predictions = []\n",
    "# for p in predictions_probs:\n",
    "#     if p[0] > 0.4:\n",
    "#          new_predictions.append(0)\n",
    "#     else:\n",
    "#         new_predictions.append(1)\n",
    "        \n",
    "# print(metrics.confusion_matrix(test_label, predictions))\n",
    "# print (metrics.accuracy_score(test_label, predictions),\n",
    "#             metrics.precision_score(test_label, predictions),\n",
    "#             metrics.recall_score(test_label, predictions),\n",
    "#             metrics.f1_score(test_label, predictions))\n",
    "\n",
    "# print(metrics.confusion_matrix(test_label, new_predictions))\n",
    "# print (metrics.accuracy_score(test_label, new_predictions),\n",
    "#             metrics.precision_score(test_label, new_predictions),\n",
    "#             metrics.recall_score(test_label, new_predictions),\n",
    "#             metrics.f1_score(test_label, new_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:0.55 Precission:0.62 Recall:0.52 F1:0.56 -> [NB Count]\n",
    "Accuracy:0.51 Precission:0.88 Recall:0.49 F1:0.63 -> [NB TFIDF]\n",
    "Accuracy:0.52 Precission:0.58 Recall:0.49 F1:0.53 -> [NB TFIDF NGram]\n",
    "Accuracy:0.49 Precission:0.96 Recall:0.48 F1:0.64 -> [NB TFIDF NGram Chars]\n",
    "Accuracy:0.55 Precission:0.69 Recall:0.52 F1:0.60 -> [NB LDA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# linear_parameters = {'penalty':('l1', 'l2'), 'C':[10, 1, 0.1, 0.01]}\n",
    "# linear_model = GridSearchCV(LogisticRegression(solver='saga'), scoring = \"f1\",param_grid = linear_parameters, cv=5)\n",
    "\n",
    "# linear_model.fit(train_count, train_label)\n",
    "\n",
    "# predictions = linear_model.predict(test_count)\n",
    "\n",
    "# (metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "\n",
    "# print(linear_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62411348 0.67973856 0.656      0.66225166 0.65693431] 0.655807599893458\n",
      "[0.58252427 0.65979381 0.62264151 0.64       0.51111111] 0.6032141413645447\n",
      "[0.58064516 0.6728972  0.71698113 0.61538462 0.5060241 ] 0.6183864402795268\n",
      "[0.64       0.64       0.55172414 0.671875   0.68907563] 0.638534953636627\n",
      "[0.60416667 0.61052632 0.64761905 0.6        0.51685393] 0.5958331925318915\n",
      "[0.58181818 0.53333333 0.60176991 0.57142857 0.46315789] 0.5503015785642706\n"
     ]
    }
   ],
   "source": [
    "# linear_config = {\n",
    "#     \"Linear Count\": (LogisticRegression(C= 0.1, penalty='l1', tol=0.1, solver='saga'), train_count, test_count)\n",
    "#     , \"Linear TFIDF\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), train_tfidf, test_tfidf)\n",
    "#     , \"Linear TFIDF NGram\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), train_tfidf_ngram, test_tfidf_ngram)\n",
    "#     , \"Linear TFIDF NGram Chars\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "# #     , \"Linear FastText Embedding\": (LogisticRegression(solver='lbfgs', max_iter=int(1e6)), train_fasttext_embedding, test_fasttext_embedding)\n",
    "#     , \"Linear LDA\": (LogisticRegression(solver='lbfgs'), train_lda, test_lda)\n",
    "#     , \"Linear Doc2Vec\": (LogisticRegression(solver='lbfgs'), train_doc2vec, test_doc2vec)\n",
    "# }\n",
    "\n",
    "# run_model(linear_config)\n",
    "\n",
    "linear_config = {\n",
    "    \"Linear Count\": (LogisticRegression(C= 0.1, penalty='l1', tol=0.1, solver='saga'), labeled_count, LABELS)\n",
    "    , \"Linear TFIDF\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), labeled_tfidf, LABELS)\n",
    "    , \"Linear TFIDF NGram\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), labeled_tfidf_ngram, LABELS)\n",
    "    , \"Linear TFIDF NGram Chars\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), labeled_tfidf_ngram_chars, LABELS)\n",
    "    , \"Linear LDA\": (LogisticRegression(solver='lbfgs'), labeled_lda, LABELS)\n",
    "    , \"Linear Doc2Vec\": (LogisticRegression(solver='lbfgs'), labeled_doc2vec, LABELS)\n",
    "}\n",
    "\n",
    "eval_model(linear_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# svm_parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10, 100], \"gamma\": np.logspace(-2, 2, 5)}\n",
    "# svm_model = GridSearchCV(SVC(), scoring = \"f1\", param_grid = svm_parameters, cv=5)\n",
    "\n",
    "# svm_model.fit(train_tfidf_ngram_chars, train_label)\n",
    "\n",
    "# predictions = svm_model.predict(test_tfidf_ngram_chars)\n",
    "\n",
    "# print(metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "# print(svm_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.675      0.6625     0.65822785 0.66216216 0.65771812] 0.6631216262137595\n",
      "[0.58695652 0.56818182 0.55913978 0.60674157 0.42666667] 0.549537272913512\n",
      "[0.58333333 0.62626263 0.71428571 0.56       0.56179775] 0.6091358853381326\n",
      "[0.67096774 0.67114094 0.63380282 0.64827586 0.67647059] 0.6601315897476935\n",
      "[0.53932584 0.43037975 0.49411765 0.56097561 0.27272727] 0.4595052238148532\n",
      "[0.69064748 0.60150376 0.59259259 0.68181818 0.65625   ] 0.6445624031647318\n"
     ]
    }
   ],
   "source": [
    "# svm_config = {\n",
    "#     \"SVM Count\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_count, test_count),\n",
    "#     \"SVM TFIDF\": (SVC(C = 10, gamma = 0.01, kernel='rbf'), train_tfidf, test_tfidf),\n",
    "#     \"SVM TFIDF NGram\": (SVC(C = 1, gamma = 0.01, kernel='linear'), train_tfidf_ngram, test_tfidf_ngram),\n",
    "#     \"SVM TFIDF NGram Chars\": (SVC(C = 10, gamma = 0.01, kernel='rbf'), train_tfidf_ngram_chars, test_tfidf_ngram_chars),\n",
    "# #     \"SVM FastText Embedding\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_fasttext_embedding, test_fasttext_embedding),\n",
    "#     \"SVM LDA\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_lda, test_lda),\n",
    "#     \"SVM Doc2Vec\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_doc2vec, test_doc2vec),\n",
    "# }\n",
    "    \n",
    "# run_model(svm_config)\n",
    "\n",
    "svm_config = {\n",
    "    \"SVM Count\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), labeled_count, LABELS),\n",
    "    \"SVM TFIDF\": (SVC(C = 10, gamma = 0.01, kernel='rbf'), labeled_tfidf, LABELS),\n",
    "    \"SVM TFIDF NGram\": (SVC(C = 1, gamma = 0.01, kernel='linear'), labeled_tfidf_ngram, LABELS),\n",
    "    \"SVM TFIDF NGram Chars\": (SVC(C = 10, gamma = 0.01, kernel='rbf'), labeled_tfidf_ngram_chars, LABELS),\n",
    "    \"SVM LDA\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), labeled_lda, LABELS),\n",
    "    \"SVM Doc2Vec\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), labeled_doc2vec, LABELS),\n",
    "}\n",
    "\n",
    "eval_model(svm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {'n_estimators':[100, 200, 500], 'max_features':[None, 0.25, 0.5, 0.75],\n",
    "                'max_depth': [None, 5, 10], 'min_samples_leaf': [0.0005, 0.01, 0.05, 0.1],\n",
    "                 'min_samples_split':[2, 5, 10]}\n",
    "rf_model = GridSearchCV(RandomForestClassifier(), scoring = \"f1\", param_grid = rf_parameters, cv=5)\n",
    "\n",
    "rf_model.fit(labeled_doc2vec, LABELS)\n",
    "\n",
    "print(rf_model.best_score_)\n",
    "print(rf_model.best_params_)\n",
    "# predictions = rf_model.predict(test_tfidf_ngram_chars)\n",
    "\n",
    "# print(metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "# print(rf_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59459459 0.65486726 0.61946903 0.66071429 0.61386139] 0.6287013099266671\n",
      "[0.61386139 0.64864865 0.59615385 0.66666667 0.54945055] 0.6149562194116649\n",
      "[0.58139535 0.55913978 0.58064516 0.53932584 0.45      ] 0.5421012275540795\n",
      "[0.61386139 0.60952381 0.55045872 0.62264151 0.60416667] 0.6001304174718765\n",
      "[0.62068966 0.62385321 0.57391304 0.66666667 0.46808511] 0.5906415365418989\n",
      "[0.67272727 0.61946903 0.58928571 0.65454545 0.54166667] 0.6155388269547563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_config = {\n",
    "    \"RF Count\": (RandomForestClassifier(criterion = 'entropy', n_estimators = 100), labeled_count, LABELS),\n",
    "    \"RF TFIDF\": (RandomForestClassifier(criterion = 'entropy', n_estimators = 200), labeled_tfidf, LABELS),\n",
    "    \"RF TFIDF NGram\": (RandomForestClassifier(criterion = 'gini', n_estimators = 200), labeled_tfidf_ngram, LABELS),\n",
    "    \"RF TFIDF NGram Chars\": (RandomForestClassifier(criterion = 'entropy', n_estimators = 200), labeled_tfidf_ngram_chars, LABELS),\n",
    "    \"RF LDA\": (RandomForestClassifier(criterion = 'gini', n_estimators = 300), labeled_lda, LABELS),\n",
    "    \"RF Doc2Vec\": (RandomForestClassifier(criterion = 'gini', n_estimators = 300), labeled_doc2vec, LABELS),\n",
    "}\n",
    "\n",
    "eval_model(rf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# xgb_parameters = {\n",
    "#         'min_child_weight': [1, 5, 10],\n",
    "#         'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'max_depth': [3, 4, 5]\n",
    "#         }\n",
    "\n",
    "# xgb_model = GridSearchCV(XGBClassifier(), scoring = \"f1\", param_grid = xgb_parameters, cv=5, verbose = 3)\n",
    "\n",
    "# xgb_model.fit(train_count, train_label)\n",
    "\n",
    "# predictions = xgb_model.predict(test_count)\n",
    "\n",
    "# print(metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "\n",
    "# print(xgb_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.61111111 0.5631068  0.65420561 0.56      ] 0.6110180362741835\n",
      "[0.625      0.60377358 0.59459459 0.62385321 0.58585859] 0.606615995273603\n",
      "[0.63366337 0.62857143 0.62264151 0.58333333 0.61538462] 0.6167188506119947\n",
      "[0.4952381  0.62711864 0.55855856 0.55238095 0.59405941] 0.5654711312371995\n",
      "[0.55462185 0.57657658 0.61111111 0.65454545 0.52336449] 0.5840438953907892\n",
      "[0.54205607 0.5631068  0.65517241 0.66666667 0.51612903] 0.5886261967201389\n"
     ]
    }
   ],
   "source": [
    "# xgboost_config = {\n",
    "#     \"XGBoost Count\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_count, test_count)\n",
    "#     , \"XGBoost TFIDF\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_tfidf, test_tfidf)\n",
    "#     , \"XGBoost TFIDF NGram\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_tfidf_ngram.tocsc(), test_tfidf_ngram.tocsc())\n",
    "#     , \"XGBoost TFIDF NGram Chars\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "#     , \"XGBoost LDA\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_lda, test_lda)\n",
    "#     , \"XGBoost Doc2Vec\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_doc2vec, test_doc2vec)\n",
    "# }\n",
    "\n",
    "# xgboost_config = {\n",
    "#     \"XGBoost Count\": (XGBClassifier(), train_count, test_count)\n",
    "#     , \"XGBoost TFIDF\": (XGBClassifier(), train_tfidf, test_tfidf)\n",
    "#     , \"XGBoost TFIDF NGram\": (XGBClassifier(), train_tfidf_ngram.tocsc(), test_tfidf_ngram.tocsc())\n",
    "#     , \"XGBoost TFIDF NGram Chars\": (XGBClassifier(), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "#     , \"XGBoost LDA\": (XGBClassifier(), train_lda, test_lda)\n",
    "#     , \"XGBoost Doc2Vec\": (XGBClassifier(), train_doc2vec, test_doc2vec)\n",
    "# }\n",
    "\n",
    "# run_model(xgboost_config)\n",
    "\n",
    "xgboost_config = {\n",
    "    \"XGBoost Count\": (XGBClassifier(), labeled_count, LABELS)\n",
    "    , \"XGBoost TFIDF\": (XGBClassifier(), labeled_tfidf, LABELS)\n",
    "    , \"XGBoost TFIDF NGram\": (XGBClassifier(), labeled_tfidf_ngram, LABELS)\n",
    "    , \"XGBoost TFIDF NGram Chars\": (XGBClassifier(), labeled_tfidf_ngram_chars, LABELS)\n",
    "    , \"XGBoost LDA\": (XGBClassifier(), labeled_lda, LABELS)\n",
    "    , \"XGBoost Doc2Vec\": (XGBClassifier(), labeled_doc2vec, LABELS)\n",
    "}\n",
    "\n",
    "eval_model(xgboost_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 51]\n",
      " [ 5 51]]\n",
      "0.4909090909090909 0.5 0.9107142857142857 0.6455696202531646\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "_dictionary = corpora.Dictionary(train_stemmed_text)\n",
    "train_doc_count = [_dictionary.doc2bow(_doc) for _doc in train_stemmed_text]\n",
    "test_doc_count = [_dictionary.doc2bow(_doc) for _doc in test_stemmed_text]\n",
    "\n",
    "tfidf_model = models.TfidfModel(train_doc_count)\n",
    "train_doc_tfidf = [dict(_doc) for _doc in tfidf_model[train_doc_count]]\n",
    "train_doc_tfidf = [(_doc, train_label[train_label.index[i]]) for i, _doc in enumerate(train_doc_tfidf)]\n",
    "test_doc_tfidf = [dict(_doc) for _doc in tfidf_model[test_doc_count]]\n",
    "\n",
    "train_doc_count = [(dict(_doc), train_label[train_label.index[i]]) for i, _doc in enumerate(train_doc_count)]\n",
    "test_doc_count = [dict(_doc) for _doc in test_doc_count]\n",
    "\n",
    "NB_classifier_count = NaiveBayesClassifier.train(train_doc_count)\n",
    "\n",
    "predictions = NB_classifier_count.classify_many(test_doc_count)\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print(metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 54]\n",
      " [ 0 56]]\n",
      "0.509090909090909 0.509090909090909 1.0 0.6746987951807228\n"
     ]
    }
   ],
   "source": [
    "NB_classifier_tfidf = NaiveBayesClassifier.train(train_doc_tfidf)\n",
    "predictions = NB_classifier_tfidf.classify_many(test_doc_tfidf)\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print(metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0]\n",
      " [56  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geesi\\Anaconda3\\envs\\dm_cap_mkl_py3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\geesi\\Anaconda3\\envs\\dm_cap_mkl_py3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4909090909090909 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "DT_classifier_count = DecisionTreeClassifier.train(train_doc_tfidf)\n",
    "predictions = DT_classifier_count.classify_many(test_doc_tfidf)\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print(metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
