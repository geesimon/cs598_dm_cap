{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:\n",
    "* [NLTK](http://www.nltk.org/howto/classify.html)\n",
    "* [SpaCy](https://spacy.io/)\n",
    "* [AllenNLP](https://allennlp.org/tutorials)\n",
    "\n",
    "Articles:\n",
    "* [A Comprehensive Guide to Understand and Implement Text Classification in Python](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)\n",
    "* [Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "* [State-of-the-Art Text Classification using BERT model: “Predict the Happiness” Challenge](https://appliedmachinelearning.blog/2019/03/04/state-of-the-art-text-classification-using-bert-model-predict-the-happiness-hackerearth-challenge/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 546/546 [00:09<00:00, 56.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text, min_len = 4):\n",
    "        if token not in STOPWORDS:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "with open(\"./data/raw/Hygiene/hygiene.dat.labels\") as f:\n",
    "    LABELS = [int(l) for l in f.readlines() if l[0].isdigit()]\n",
    "\n",
    "ALL_TEXTS = []\n",
    "LABELED_TEXTS = []\n",
    "with open(\"./data/raw/Hygiene/hygiene.dat\") as f:\n",
    "    ALL_TEXTS = f.readlines()\n",
    "    for i in range(0, len(LABELS)):\n",
    "        LABELED_TEXTS.append(ALL_TEXTS[i])\n",
    "\n",
    "LABELED_STEMMED_TEXTS = [preprocess(_text) for _text in tqdm(LABELED_TEXTS)]\n",
    "LABELED_RAW_STEMMED_TEXTS = [\" \".join(_text) for _text in LABELED_STEMMED_TEXTS]\n",
    "\n",
    "FEATURE_MORE =pd.read_csv(\"./data/raw/Hygiene/hygiene.dat.additional\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using texts and lables\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = LABELED_RAW_STEMMED_TEXTS\n",
    "trainDF['label'] = LABELS\n",
    "\n",
    "# split the dataset into training and validation datasets \n",
    "train_text, test_text, train_label, test_label = model_selection.train_test_split(trainDF['text'], \n",
    "                                                                                  trainDF['label'],\n",
    "                                                                                  test_size = 0.2)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_label = encoder.fit_transform(train_label)\n",
    "test_label = encoder.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = corpora.Dictionary(processed_docs)\n",
    "# print(\"Before prunn:%d\"%(len(dictionary)))\n",
    "# dictionary.filter_extremes(no_below = 2, no_above = 0.5)\n",
    "# print(\"After prunn:%d\"%(len(dictionary)))\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_df = 0.5)\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "train_count =  count_vect.transform(train_text)\n",
    "test_count =  count_vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 s, sys: 170 ms, total: 9.17 s\n",
      "Wall time: 8.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "train_tfidf =  tfidf_vect.transform(train_text)\n",
    "test_tfidf =  tfidf_vect.transform(test_text)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word',ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "train_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_text) \n",
    "test_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'access googl street view like medina yarrow point weird come pictur exterior yelper stop take snapshot good restaur tire mazatlan puerto vallarta azteca squar footag smaller guess peopl assum tabl right away realiti probabl wait come complimentari chip salsa want guacamol mind complimentari burrita littl spici kick couldn huge like alki think wait till summertim decid place neighborhood better time like alki locat know love servic outstand navajo torta bland good textur butternut squash enchilada mmmmmm vegetarian option best good flavor sauc time wrong sauc didnt tast delici like char asparagus zing interest tasti light good fruiti ice sweet like fruiti ice tea burn crave great madison park cactus favorit cactus locat locat charm quaint madison park area nice vibe summer night pretti perfect restaur pack cactus usual spot tabl area open window fantast breez nice view madison park happen quick agre good get love start drink friend order margarita baja jalapeno fruiti cocktail guacamol tortilla chip guac pretti tasti nice zing food order half order nacho sucker nacho husband order grill portobello veget escabech fajita offici claim announc fajita best life hear mention fajita time morn busi obsess nacho roast corn melt chees pico gallo buttermilk crema guac take small bite fajita import statement portabella anymor season nice gentl kick touch lime cactus pretti particular locat remain favorit spot excit south lake union dig open soon solid spot fresh tasti food good food good servic waiter differ locat hour later recogn thank come dedic servic say manag come bring free flan come definit enjoy normal want spend mexican food especi want chip salsa food worth mexican place chip salsa appar bottomless portion fill grossli larg flavor incred uniqu cactus outsid drink special enjoy hole wall mexican restaur whimsic place interest uniqu varieti food match mojito chile relleno friend recommend complet blow away flavor care go present thumb night friend softbal game cowork plenti time come cactus year satisfi start hous salsa guacamol chip salsa delici great lime flavor order lemonad jalap refresh wish drink tri dish favorit mexican chop salad great lime dress tender chicken chicken taco pretti fantast good fixin favorit probabl chicken chimayo blue corn tortilla green chile sauc mix melt chees fantast bread honey pretti good honey warm bread combo awesom mind mexican mexican southwest fusion dish tradit love cactus chip salsa spot think best flan sangria light refresh tri dish time come enjoy thorough atmospher great decor color servic superb chat feel like rush great option hanker delicioso cactus slight differ edg mexican restaur focus southwest cuisin coupl popular item menu item sound like tasti appet guacamol appet squash blossom stuff goat chees sonora chicken butternut squash enchilada quesadilla grill steak flanso start salsa serv tabl addict love scar go eat tortilla chip chip light greasi guacamol look nice larg portion garnish nice wasn dillut avocado receiv smaller portion plain avocado wonder paradis brand passion fruit haven love bring memori squash blossom goat chees closest similar come mind like crab rangoon fri creami chees serv differ type sauc chipotl cilantro garlic smokey sauc sauc fine squash blossom problem serv price plate basket easili like serv corn chip guacamol smear sonora chicken pretti tasti like grill chicken veget present wasn favorit tast better look wife butternut squash enchilada plate huge come black bean rice massiv enchilada thing usual type bean black bean rice good main add pepita toast squash seed give nice bite crunch enchilada hearti tasti fill squash massiv portabella mushroom insid flavor exceed present look bore tast mejor kid quesadilla quesadilla grill steak small piec steak meat daughter munch steak meat polish dessert split flan server say type milk give creami finish jason server right delici tast like dens calori sure like term look feel restaur kind noisi daughter like tiger fabric booth seat light littl menu felt littl like great like get alcohol beverag kid feel famili like food overal pretti tasti littl pricey present littl better emphas qualiti meal point decor point cook steak fajita point good salsa okay guacamol point crappi lacklust servic point sopapilla dessertend restaur week accid place understaf busi sunday afternoon crowd host phone walk happen fail acknowledg happen take seat admir decor chit chat check phone start final bartend menus wait minut come tabl bartend come mumbl special avail restaur week order drink food come lemon hard garnish right offer sweeten rocket scienc offer free chip salsa free guacamol come later fajita come steak cook order fajita plenti peopl burn tortilla quick restaur serv tortilla peopl want bring tortilla pay leav say yelp review cactus usual pretti good tell slam staff bust butt tabl decent select vegetarian option includ veget oppos chees enchilada servic today miss order margarita grand marnier cinnamon sugar salt uniqu cocktail tasti order special menu forget call egg cornmeal steak potato delici normal rude tabl girlfriend ask bite say manag bring complimentari flan time flan good impress bring definit come nacho best planet split peopl mojito perfect friday work meat nacho good husband go birthday dinner staff great especi waitress cynara friend attent hover like seagul food good expect typic mexican american food emphasi cumin huge food enjoy hibiscus girl drink drink banana dulc good want home meet parent great place classi casual even price decent love love love cactus go time saturday enjoy dinner patio food take littl longer like enjoy mojito delici salsa amaz dinner compani sampl chicken taco chicken chimichanga delici wait butternut squash enchilada finish manag come welcom complimentari flan beat food good chip salsa plus guacamol cost instead free mexican restaur refil chip fajita beef green enchilada tast fresh cactus margarita come simpl glass sweet salt overal atmospher relax nice hard feel real mexican seattl sunni sunday lunch get pretti close drive park street servic slow unbear experi decent come friend lunch weekday texa search place seattl offer cuisin honest place servic excel food passabl unremark liken arizona texa mexico wasn unremark fair bland tast fair fresh lack zing speak look mexican food place go time today staff fantast work food servic difficult muster enthusiasm peopl genuin excit food role host delici chimichanga guacamol great time experi worth brisket taco amaz tri seafood enchilada wife good finish definit go good thing place cactus spot everytim seattl food impress servic make place place citi great din nice outsid wait outdoor tabl beat hang enjoy food watch madison park crazi sure seattl know head stellar experi salsa good jalapeno popper spici hell good server super nice manag give free dessert reason tell free flan pretti fuck good custom servic feel mention busi friday night bartend great friend fast wait tabl come long enjoy awesom waiter food servic pretti quick food concern good mexican joint come consid get food poison twice life mexican food definit recommend place find madison park awesom restaur great food great drink good vibe good locat madison park high standard live austin texa year place best leav texa servic impecc food take time arriv time folk seat say word manag come tabl apolog give desert home good servic place wrong boyfriend go celebr anniversari favorit place amaz chile relleno coconut rice everyday know world thing best meal mention chip salsa start wonder best boyfriend chicken fri chicken phenomen servic great love place remain loyal custom forev place fantast visit staff friend welcom inform help question menu salsa chip desert fantast leav stuff want food delici margarita good perfect go soon boyfriend work summer rave food occasion bring home entic final break go visit glad food delight guacamol bread steak salad especi especi butternut squash enchilada tri love cocktail inspir tasti unfortun haven boyfriend leav stop get sweet hook happi hour return come friend light dinner mistak think pass light food matter order pineappl margarita delici dinner order chicken chimichanga chimichanga pack chicken slather jack chees chicken wasn greasi great come black bean rice guacamol sour cream chicken moist cook overal wouldn extraordinari definit execut dish fine portion dish perfect relat littl plate food atmospher nice choos outsid tabl wasn huge size plat glass fine servic fine waiter pleasant madison park area look restaur east madison street strip place worthi money love cactus madison park favorit second time rave place disappiont servic girfriend bartendar slam felt neglect fantast boss step especi chaotic great place host wait person food tast present properti ambianc style decor cactus regular rotat dinner cactus margarita saltth best damn chip salsa towntortilla soup scarf middl summer degre outa steak salad like salad mix green toss sear skirt steak slice avocado blue chees pico gallo yummi flan put custard dessert shame delici serv attent friend staff piti nice weather make wait plenti place nearbi walk drink wait remodel order bitch prior review miss charm fuck time cram top cactusgo steak chicken salad peopl visit seattl move friend take cactus southern california familiar mexican food cactus rais creativ add flair visit seafood enchilada good nice flavor perfect cook black bean rice order sangria tasti special blacken chicken tamal phenomen great spice flavor lay lake sweet corn relish sauc good meal order order churro dip sauc mexican carmel dark chocol sauc reminisc bosco coconut whip cream absolut amaz great meal time like cactus come friend outsid great peopl watch nice summer even like feel insid good louder group casual date outsid order veggi enchilada longer appear menu good want cocktail dessert dish seafood enchilada butternut squash enchilada cuban flan banana dulc excit lake union locat open especi happi hour locat chop salad park best use southwestern flavor enjoy time root food seattl locat twice kirkland interest drink menu servic horribl atleast seattl locat go wednesday night busi soon step person wait door host person believ host walk right hello right tabl area want miss coupl walk consider long wait tabl place worth wait final tell grab tabl wait wait bring menu water eventu din need feel take twice long like understaf staff stand order regist talk eachoth instead help reason madison area restaur live close marvel establish allow frequent awesom margarita wonder chip guacamol hearti innov inspir spanish dish madison park come difficult tabl great place drink merri food amaz veggi burrito lunch menu order abl dinner fantast beauti actual like feel mean ruin present servic inconsist phenomen stellar potenti time come order vegetarian item receiv chicken prawn instead note mistak meal complementari drink copious amount guac dessert mother go dinner expect usual wait girl curt say hour parti accept walk come wait minut disgust open booth tabl tabl slide accommod booth open wait hour buzzer ring booth wait watch booth remain time leav bummer appar ahead list lessen wait tasti food nacho appet ador plop guac tasti cover chip cute expens small place food pretti good prepar wait long tabl popular joint servic notch kind chipotl browni dessert sin good probabl park wait hour tabl cactus item menu best categori citi best mojito flavor good pomegran mango favorit miss coconut best tamal earli tamal usual special quick best salad mexican chop salad best best best chorizo nacho hard mess nacho plenti place decent good one fact fast food world offer pretti good nacho want best cactus order chorizo finger exact make nacho superior mayb sauc instead sour cream buttermilk crema nacho delici chorizo chorizo nacho place haven good cactus make chorizo edg sauc chorizo combin factor assur best nacho tast need peopl finish order luckili offer half order honest disappoint cactus hundr time frequent kirkland live pleasant surpris move madison park definit favorit mexican restaur greasi drown chees type mexican food place serv fresh delici interest plat butternut squash enchilada think put delici green enchilada person favorit steak taco cook steak perfect meal come top appetit desir taco prickley pear margarita guacamol rank best guac decor funki cool zebra strip booth light lantern hang ceil great spot date drink free chip salsa better cactus worker unit come celebr colleagu retir boss choos pick place know expect time thing notic walk insid beauti place love decor felt complet comfort minut walk walk right restroom staight ahead seat rest parti immedi start order drink soon parti arriv long island ice good strong pluse attent custom want felt feel waiter food serv chip salsa yummi take time order entre receiv issu food butternut squash good vegan version enchilada spici worker order thing like meal order thing place keep clean size medium size restaraunt despit have best meal place second shoot high recommend green enchilada best item menu staff nice super busi cactus madison park institut good reason best mexican food servic long time waitress excel decor gaudi like mexican restaur endear actual add experi waitress ask time extrem help forthcom suggest husband ancho roast pork pibil butternut squash enchilada amaz mention watermelon cucumb margarita signatur award win margarita delici refresh high qualiti thing better manag bring surpris flan thank come restaur nice person experi time total complet impress wonder food excel drink dealmak servic server best rememb long time mayb fals excel actual treat waiter like felt welcom definit'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELED_RAW_STEMMED_TEXTS[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('data/model/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "text_train_seq = sequence.pad_sequences(token.texts_to_sequences(train_text), maxlen=70)\n",
    "text_test_seq = sequence.pad_sequences(token.texts_to_sequences(test_text), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 s, sys: 763 ms, total: 35.3 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "model = FastText(size = 100, window = 5, min_count = 5)\n",
    "model.build_vocab(sentences = LABELED_STEMMED_TEXTS)\n",
    "model.train(sentences = LABELED_STEMMED_TEXTS, total_examples = len(LABELED_STEMMED_TEXTS), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text / NLP based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import textblob\n",
    "\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Models as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(text_train_count)\n",
    "topic_word = lda_model.components_\n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
