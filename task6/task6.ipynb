{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:\n",
    "* [NLTK](http://www.nltk.org/howto/classify.html)\n",
    "* [SpaCy](https://spacy.io/)\n",
    "* [AllenNLP](https://allennlp.org/tutorials)\n",
    "\n",
    "Articles:\n",
    "* [A Comprehensive Guide to Understand and Implement Text Classification in Python](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)\n",
    "* [Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "* [State-of-the-Art Text Classification using BERT model: “Predict the Happiness” Challenge](https://appliedmachinelearning.blog/2019/03/04/state-of-the-art-text-classification-using-bert-model-predict-the-happiness-hackerearth-challenge/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13299/13299 [03:48<00:00, 58.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    result_stemmed = []\n",
    "    for token in simple_preprocess(text, min_len = 2):\n",
    "        result.append(token)\n",
    "        if token not in STOPWORDS:\n",
    "            result_stemmed.append(lemmatize_stemming(token))\n",
    "    \n",
    "    return (result, result_stemmed)\n",
    "\n",
    "with open(\"./data/raw/Hygiene/hygiene.dat.labels\") as f:\n",
    "    LABELS = [int(l) for l in f.readlines() if l[0].isdigit()]\n",
    "\n",
    "ALL_RAW_TEXTS = []\n",
    "ALL_TEXTS = []\n",
    "ALL_STEMMED_TEXTS = []\n",
    "ALL_CONCAT_STEMMED_TEXTS = []\n",
    "LABELED_TEXTS = []\n",
    "LABELED_CONCAT_TEXTS = []\n",
    "LABELED_STEMMED_TEXTS = []\n",
    "LABELED_CONCAT_STEMMED_TEXTS = []\n",
    "\n",
    "with open(\"./data/raw/Hygiene/hygiene.dat\") as f:\n",
    "    ALL_RAW_TEXTS = f.readlines()\n",
    "\n",
    "for _text in tqdm(ALL_RAW_TEXTS):\n",
    "    _result, _result_stemmed = preprocess(_text)\n",
    "    ALL_TEXTS.append(_result)\n",
    "    ALL_STEMMED_TEXTS.append(_result_stemmed)\n",
    "\n",
    "ALL_CONCAT_STEMMED_TEXTS = [\" \".join(_text) for _text in ALL_STEMMED_TEXTS]\n",
    "\n",
    "LABELED_TEXTS = ALL_TEXTS[0:len(LABELS)]\n",
    "LABELED_CONCAT_TEXTS = [\" \".join(_text) for _text in LABELED_TEXTS]\n",
    "\n",
    "LABELED_STEMMED_TEXTS = ALL_STEMMED_TEXTS[0:len(LABELS)]\n",
    "LABELED_CONCAT_STEMMED_TEXTS = [\" \".join(_text) for _text in LABELED_STEMMED_TEXTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handle Extra Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_map = 'abcdefghij'\n",
    "code_map = '0123456789'\n",
    "\n",
    "def encode_zipcode(zip_code):\n",
    "    _code = ''\n",
    "    _rest = zip_code    \n",
    "    while _rest > 0:\n",
    "        _code = code_map[_rest % 10] + _code\n",
    "        _rest = int(_rest / 10)\n",
    "\n",
    "    return _code\n",
    "\n",
    "FEATURE_MORE =pd.read_csv(\"./data/raw/Hygiene/hygiene.dat.additional\", header=None)\n",
    "EXTRA_FEATURE = pd.DataFrame()\n",
    "\n",
    "EXTRA_FEATURE['Cuisines'] = [simple_preprocess(_text) for _text in FEATURE_MORE[0]]\n",
    "\n",
    "EXTRA_FEATURE['Stars'] = ['PoorStars' for _star in FEATURE_MORE[3]]\n",
    "star_std_range = (FEATURE_MORE[3].mean() - FEATURE_MORE[3].std(), FEATURE_MORE[3].mean() + FEATURE_MORE[3].std())\n",
    "# EXTRA_FEATURE['Stars'][FEATURE_MORE[3] < star_std_range[0]] = 'PoorStars'\n",
    "EXTRA_FEATURE['Stars'][(FEATURE_MORE[3] >= star_std_range[0])] = 'StandardStars'\n",
    "EXTRA_FEATURE['Stars'][FEATURE_MORE[3] > star_std_range[1]] = 'GoodStars'\n",
    "\n",
    "EXTRA_FEATURE['ReviewCount'] = ['NoReviews' for _star in FEATURE_MORE[2]]\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 2] = \"FewReviews\"\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 6] = \"SomeReviews\"\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 13] = \"ManyReviews\"\n",
    "EXTRA_FEATURE['ReviewCount'][FEATURE_MORE[2] > 50] = \"LotReviews\"\n",
    "\n",
    "EXTRA_FEATURE['ZIPCode'] = [encode_zipcode(_code) for _code in FEATURE_MORE[1]]\n",
    "\n",
    "EXTRA_FEATURE['MergedText'] = [ [_cuisine for _cuisine in _record[1][0]]\n",
    "                                + [_record[1][1]] + [_record[1][2]] + [_record[1][3]]\n",
    "                               for _record in EXTRA_FEATURE.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vietnamese,sandwiches,restaurants,StandardStars,FewReviews,98118'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(EXTRA_FEATURE['MergedText'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Extra Features to the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELED_EXTRA_TEXTS = EXTRA_FEATURE['MergedText'][0:len(LABELS)]\n",
    "LABELED_CONCAT_EXTRA_TEXTS = [\",\".join(_text) for _text in LABELED_EXTRA_TEXTS]\n",
    "\n",
    "LABELED_TEXTS = [LABELED_EXTRA_TEXTS[i] + _text for i, _text in enumerate(LABELED_TEXTS)]\n",
    "LABELED_CONCAT_TEXTS = [\" \".join(_text) for _text in LABELED_TEXTS]\n",
    "\n",
    "LABELED_STEMMED_TEXTS = [LABELED_EXTRA_TEXTS[i] + _text for i, _text in enumerate(LABELED_STEMMED_TEXTS)]\n",
    "LABELED_CONCAT_STEMMED_TEXTS = [\" \".join(_text) for _text in LABELED_STEMMED_TEXTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABLED_RAW_TEXTS_1 = [LABELED_CONCAT_EXTRA_TEXTS[i] + \"|\" + _text for i, _text in enumerate(ALL_RAW_TEXTS[0:len(LABELS)]) if LABELS[i] == 1]\n",
    "LABLED_RAW_TEXTS_0 = [LABELED_CONCAT_EXTRA_TEXTS[i] + \"|\" + _text for i, _text in enumerate(ALL_RAW_TEXTS[0:len(LABELS)]) if LABELS[i] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 52\n"
     ]
    }
   ],
   "source": [
    "SMALL_RAW_TEXTS_1 = [_text for _text in LABLED_RAW_TEXTS_1 if len(_text) < 1000]\n",
    "SMALL_RAW_TEXTS_0 = [_text for _text in LABLED_RAW_TEXTS_0 if len(_text) < 1000]\n",
    "print(len(SMALL_RAW_TEXTS_1), len(SMALL_RAW_TEXTS_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"breakfast,brunch,greek,restaurants,StandardStars,NoReviews,98199|Tickled to find a good breakfast in Magnolia - because there aren't any others. Great home cooking - thin potatoes and two great eggs. Coffee, orange juice and the Greek language.Perfect early morning.\\n\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMALL_RAW_TEXTS_1[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pizza,restaurants,GoodStars,NoReviews,98109|Pizza Hut Internet Delivery is uncomplicated. They take cash and credit orders. Gave me an estimated time of delivery. And emailed the receipt. Really simple.A timely delivery in rain was enough to impress me. But the delivery woman was smiling and courteous. She gave me parmesan and pepper packets. Thanks.Pizza Hut couldn't stop there.... The Veggie-Lovers Pizza came piping hot. It was adorned by tons of fresh chopped veggies like more than I expected. So much so that the sauce couldn't even peek. Fer real.And today is Pizza Hut's Wing Wednesday. Thus decided to add some boneless wings with ranch dressing to my pizza order. Too much food. But it'll make enjoyable leftovers. Also they gave me a free liter of the new Pepsi Max on top of their newly lowered pizza prices. Sinful spinster.... I am!\\n\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMALL_RAW_TEXTS_0[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using texts and lables\n",
    "labeled_df = pd.DataFrame()\n",
    "labeled_df['concat_stemmed_text'] = LABELED_CONCAT_STEMMED_TEXTS\n",
    "labeled_df['stemmed_text'] = LABELED_STEMMED_TEXTS\n",
    "# labeled_df['concat_stemmed_text'] = LABELED_CONCAT_TEXTS\n",
    "# labeled_df['stemmed_text'] = LABELED_TEXTS\n",
    "# labeled_df['concat_stemmed_text'] = LABELED_CONCAT_EXTRA_TEXTS\n",
    "# labeled_df['stemmed_text'] = LABELED_EXTRA_TEXTS\n",
    "labeled_df['label'] = LABELS\n",
    "\n",
    "# split the dataset into training and validation datasets \n",
    "train_concat_stemmed_text, test_concat_stemmed_text, train_label, test_label = model_selection.train_test_split(labeled_df['concat_stemmed_text'], \n",
    "                                                                                  labeled_df['label'],\n",
    "                                                                                  test_size = 0.2,\n",
    "                                                                                  random_state = 10)\n",
    "train_stemmed_text = labeled_df['stemmed_text'][train_concat_stemmed_text.index]\n",
    "test_stemmed_text = labeled_df['stemmed_text'][test_concat_stemmed_text.index]\n",
    "\n",
    "# # label encode the target variable \n",
    "# encoder = preprocessing.LabelEncoder()\n",
    "# train_label = encoder.fit_transform(train_label)\n",
    "# test_label = encoder.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = corpora.Dictionary(processed_docs)\n",
    "# print(\"Before prunn:%d\"%(len(dictionary)))\n",
    "# dictionary.filter_extremes(no_below = 2, no_above = 0.5)\n",
    "# print(\"After prunn:%d\"%(len(dictionary)))\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCountVectorizer:\n",
    "    def __init__(self, max_df = 0.5):\n",
    "        self.vect_model = CountVectorizer(analyzer='word', max_df = max_df)\n",
    "        \n",
    "    def fit(self, texts_concat):\n",
    "        self.vect_model.fit(texts_concat)\n",
    "    \n",
    "    def transform(self, texts_concat):\n",
    "        return self.vect_model.transform(texts_concat)\n",
    "\n",
    "count_vect = MyCountVectorizer()\n",
    "count_vect.fit(train_concat_stemmed_text)\n",
    "train_count = count_vect.transform(train_concat_stemmed_text)\n",
    "test_count =  count_vect.transform(test_concat_stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectors as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.44 s, sys: 180 ms, total: 8.62 s\n",
      "Wall time: 8.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# word level tf-idf\n",
    "class MyTfidfVectorizer(MyCountVectorizer):\n",
    "    def __init__(self, analyzer='word', ngram_range = None, max_features=5000):\n",
    "        if ngram_range is None:\n",
    "            self.vect_model = TfidfVectorizer(analyzer = analyzer, max_features = max_features)\n",
    "        else:\n",
    "            self.vect_model = TfidfVectorizer(analyzer = analyzer, ngram_range = ngram_range, \n",
    "                                              max_features = max_features)\n",
    "            \n",
    "    def fit(self, texts_concat):   \n",
    "        self.vect_model.fit(texts_concat)\n",
    "        self.vocabulary = self.vect_model.vocabulary_\n",
    "\n",
    "\n",
    "tfidf_vect = MyTfidfVectorizer()\n",
    "tfidf_vect.fit(train_concat_stemmed_text)\n",
    "train_tfidf =  tfidf_vect.transform(train_concat_stemmed_text)\n",
    "test_tfidf =  tfidf_vect.transform(test_concat_stemmed_text)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = MyTfidfVectorizer(ngram_range=(2,3))\n",
    "tfidf_vect_ngram.fit(train_concat_stemmed_text)\n",
    "train_tfidf_ngram =  tfidf_vect_ngram.transform(train_concat_stemmed_text)\n",
    "test_tfidf_ngram =  tfidf_vect_ngram.transform(test_concat_stemmed_text)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = MyTfidfVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "tfidf_vect_ngram_chars.fit(train_concat_stemmed_text)\n",
    "train_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_concat_stemmed_text) \n",
    "test_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_concat_stemmed_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build from review corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from gensim.models.fasttext import FastText\n",
    "\n",
    "# class MyFastTextTfidfVectorizer(MyCountVectorizer):\n",
    "#     def __init__(self, tfidf_vectorizer, size = 100):\n",
    "#         self.embedding_size = size\n",
    "#         self.tfidf_vectorizer = tfidf_vectorizer\n",
    "#         self.fasttext_model = FastText(size = size, window = 5, min_count = 5)\n",
    "\n",
    "#     def tfidf2embedding(self, value_vector):\n",
    "#         _weighted_value = np.zeros(self.embedding_size)\n",
    "#         for key in self.tfidf_vectorizer.vocabulary:\n",
    "#             _index = self.tfidf_vectorizer.vocabulary[key]\n",
    "#             if value_vector[_index] != 0:\n",
    "#                 _weighted_value += self.fasttext_model[key] * value_vector[_index]\n",
    "\n",
    "#         return _weighted_value\n",
    "    \n",
    "#     def fit(self, texts):\n",
    "#         _texts_concat = [\" \".join(_text) for _text in texts]\n",
    "#         self.tfidf_vectorizer = MyTfidfVectorizer()\n",
    "#         self.tfidf_vectorizer.fit(_texts_concat)\n",
    "        \n",
    "#         self.fasttext_model.build_vocab(sentences = texts)\n",
    "#         self.fasttext_model.train(sentences = texts, \n",
    "#                                   total_examples = len(texts), \n",
    "#                                   epochs=10)\n",
    "        \n",
    "#     def transform(self, texts):\n",
    "#         _texts_concat = [\" \".join(_text) for _text in texts]\n",
    "#         _tfidf_values = self.tfidf_vectorizer.transform(_texts_concat)\n",
    "#         return np.asarray([self.tfidf2embedding(_value.toarray()[0]) for _value in _tfidf_values])\n",
    "\n",
    "# fasttext_tfidf_vect = MyFastTextTfidfVectorizer(tfidf_vect)\n",
    "# fasttext_tfidf_vect.fit(ALL_STEMMED_TEXTS)\n",
    "# train_fasttext_embedding = fasttext_tfidf_vect.transform(train_stemmed_text)\n",
    "# test_fasttext_embedding = fasttext_tfidf_vect.transform(test_stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prebuilt Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from keras.preprocessing import text, sequence\n",
    "# from keras import layers, models, optimizers\n",
    "\n",
    "# # load the pre-trained word-embedding vectors \n",
    "# embeddings_index = {}\n",
    "# for i, line in enumerate(open('data/model/wiki-news-300d-1M.vec')):\n",
    "#     values = line.split()\n",
    "#     embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# # create a tokenizer \n",
    "# token = text.Tokenizer()\n",
    "# token.fit_on_texts(LABELED_CONCAT_STEMMED_TEXTS)\n",
    "# word_index = token.word_index\n",
    "\n",
    "# # convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "# text_train_seq = sequence.pad_sequences(token.texts_to_sequences(train_text), maxlen=70)\n",
    "# text_test_seq = sequence.pad_sequences(token.texts_to_sequences(test_text), maxlen=70)\n",
    "\n",
    "# # create token-embedding mapping\n",
    "# embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "# for word, i in word_index.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text / NLP based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "# trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "# trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "# trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "# trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "# trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import textblob\n",
    "\n",
    "# pos_family = {\n",
    "#     'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "#     'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "#     'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "#     'adj' :  ['JJ','JJR','JJS'],\n",
    "#     'adv' : ['RB','RBR','RBS','WRB']\n",
    "# }\n",
    "\n",
    "# # function to check and get the part of speech tag count of a words in a given sentence\n",
    "# def check_pos_tag(x, flag):\n",
    "#     cnt = 0\n",
    "#     try:\n",
    "#         wiki = textblob.TextBlob(x)\n",
    "#         for tup in wiki.tags:\n",
    "#             ppo = list(tup)[1]\n",
    "#             if ppo in pos_family[flag]:\n",
    "#                 cnt += 1\n",
    "#     except:\n",
    "#         pass\n",
    "#     return cnt\n",
    "\n",
    "# trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "# trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "# trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "# trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "# trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a LDA Model\n",
    "# lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "# X_topics = lda_model.fit_transform(text_train_count)\n",
    "# topic_word = lda_model.components_\n",
    "# vocab = count_vect.get_feature_names()\n",
    "\n",
    "# # view the topic models\n",
    "# n_top_words = 10\n",
    "# topic_summaries = []\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "#     topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.13 s, sys: 115 ms, total: 3.24 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "from gensim import corpora, models\n",
    "\n",
    "class MyLDAVectorizer(MyCountVectorizer):\n",
    "    mallet_path = \"..\" + os.sep + \"mallet-2.0.8\"+ os.sep + \"bin\" + os.sep +\"mallet\"\n",
    "    \n",
    "    def __init__(self, TOPIC_COUNT = 100):\n",
    "        self.topic_count = TOPIC_COUNT\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        self.dictionary = corpora.Dictionary(texts)\n",
    "        _corpus = [self.dictionary.doc2bow(_doc) for _doc in texts]\n",
    "        self.tfidf_model = models.TfidfModel(_corpus)\n",
    "        _tfidf_corpus = self.tfidf_model[_corpus]\n",
    "\n",
    "#         self.vect_model = models.LdaModel(_tfidf_corpus, \n",
    "#                             num_topics = self.topic_count, \n",
    "#                             id2word = self.dictionary,\n",
    "#                             random_state = 100,\n",
    "#                             eval_every = 5, \n",
    "#                             alpha = 'auto', \n",
    "#                             gamma_threshold = 0.01)\n",
    "        \n",
    "        self.vect_model = models.wrappers.LdaMallet(self.mallet_path, \n",
    "                                                     corpus = _corpus, \n",
    "                                                     num_topics = self.topic_count, \n",
    "                                                     id2word = self.dictionary)\n",
    "    \n",
    "    def toarray(self, doc_topics):\n",
    "        _doc_vect  = np.zeros((len(doc_topics), self.topic_count))\n",
    "        \n",
    "        for i, _doc in enumerate(doc_topics):\n",
    "            for _topic, _weight in _doc:\n",
    "                _doc_vect[i][_topic] = _weight\n",
    "        \n",
    "        return _doc_vect\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        _corpus = [self.dictionary.doc2bow(_doc) for _doc in texts]\n",
    "#         _tfidf_corpus = self.tfidf_model[_corpus]\n",
    "        \n",
    "        return self.toarray(self.vect_model[_corpus])\n",
    "\n",
    "lda_vect = MyLDAVectorizer()\n",
    "lda_vect.fit(train_stemmed_text)\n",
    "train_lda = lda_vect.transform(train_stemmed_text)\n",
    "test_lda = lda_vect.transform(test_stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.1 s, sys: 546 ms, total: 29.7 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import numpy as np\n",
    "\n",
    "class MyDoc2Vectorizer(MyCountVectorizer):\n",
    "    def __init__(self, size = 100):\n",
    "        self.embedding_size = size\n",
    "            \n",
    "    def fit(self, texts):\n",
    "        _docs = [TaggedDocument(_doc, [i]) for i, _doc in enumerate(texts)]\n",
    "        self.vect_model = Doc2Vec(_docs, \n",
    "                                  vector_size = self.embedding_size, \n",
    "#                                   window = 8,\n",
    "                                  epochs=40, \n",
    "                                  workers=4)\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        return np.asarray([self.vect_model.infer_vector(_text) for _text in texts])\n",
    "\n",
    "doc2vec_vect = MyDoc2Vectorizer(size = 200)\n",
    "# doc2vec_vect.fit(ALL_STEMMED_TEXTS)\n",
    "doc2vec_vect.fit(train_stemmed_text)\n",
    "train_doc2vec = doc2vec_vect.transform(train_stemmed_text)\n",
    "test_doc2vec = doc2vec_vect.transform(test_stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 436})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test quality\n",
    "\n",
    "import collections\n",
    "\n",
    "ranks = []\n",
    "for doc_id in range(len(train_stemmed_text)):\n",
    "    inferred_vector = doc2vec_vect.vect_model.infer_vector(train_stemmed_text[train_stemmed_text.index[doc_id]])\n",
    "    sims = doc2vec_vect.vect_model.docvecs.most_similar([inferred_vector], topn=len(doc2vec_vect.vect_model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "collections.Counter(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def show_score(classifier_name, scores):\n",
    "    print(\"Accuracy:%0.2f Precission:%0.2f Recall:%0.2f F1:%0.2f\"%scores, \"-> [%s]\"%(classifier_name))\n",
    "    \n",
    "def train_model(classifier, train_feature, train_label, test_feature, test_label, is_neural_net=False):\n",
    "#     print(train_feature)\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(train_feature, train_label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(test_feature)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    print(metrics.confusion_matrix(test_label, predictions))\n",
    "    return (metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))\n",
    "\n",
    "def run_model(classfier_configs):\n",
    "    for _name in classfier_configs:\n",
    "#         print(classfier_configs[_name].train)\n",
    "        scores = train_model(classfier_configs[_name][0], classfier_configs[_name][1], train_label, classfier_configs[_name][2], test_label)\n",
    "        show_score(_name, scores)\n",
    "        \n",
    "class ClassifierConfig:\n",
    "     def __init__(self, classifier, train, test):\n",
    "            self.classifier = classifier\n",
    "            self.train = train\n",
    "            self.test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 20]\n",
      " [20 36]]\n",
      "Accuracy:0.64 Precission:0.64 Recall:0.64 F1:0.64 -> [NB Count]\n",
      "[[29 25]\n",
      " [17 39]]\n",
      "Accuracy:0.62 Precission:0.61 Recall:0.70 F1:0.65 -> [NB TFIDF]\n",
      "[[34 20]\n",
      " [23 33]]\n",
      "Accuracy:0.61 Precission:0.62 Recall:0.59 F1:0.61 -> [NB TFIDF NGram]\n",
      "[[17 37]\n",
      " [ 8 48]]\n",
      "Accuracy:0.59 Precission:0.56 Recall:0.86 F1:0.68 -> [NB TFIDF NGram Chars]\n",
      "[[42 12]\n",
      " [27 29]]\n",
      "Accuracy:0.65 Precission:0.71 Recall:0.52 F1:0.60 -> [NB LDA]\n"
     ]
    }
   ],
   "source": [
    "nb_config = {\n",
    "    \"NB Count\": (naive_bayes.MultinomialNB(), train_count, test_count),\n",
    "    \"NB TFIDF\": (naive_bayes.MultinomialNB(), train_tfidf, test_tfidf),\n",
    "    \"NB TFIDF NGram\": (naive_bayes.MultinomialNB(), train_tfidf_ngram, test_tfidf_ngram),\n",
    "    \"NB TFIDF NGram Chars\": (naive_bayes.MultinomialNB(), train_tfidf_ngram_chars, test_tfidf_ngram_chars),\n",
    "    \"NB LDA\": (naive_bayes.MultinomialNB(), train_lda, test_lda),\n",
    "}\n",
    "\n",
    "run_model(nb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29 25]\n",
      " [17 39]]\n",
      "0.6181818181818182 0.609375 0.6964285714285714 0.65\n",
      "[[44 10]\n",
      " [26 30]]\n",
      "0.6727272727272727 0.75 0.5357142857142857 0.6250000000000001\n"
     ]
    }
   ],
   "source": [
    "nb_model = naive_bayes.MultinomialNB()\n",
    "nb_model.fit(train_tfidf, train_label)\n",
    "predictions = nb_model.predict(test_tfidf)     \n",
    "predictions_probs = nb_model.predict_proba(test_tfidf)\n",
    "\n",
    "new_predictions = []\n",
    "for p in predictions_probs:\n",
    "    if p[0] > 0.4:\n",
    "         new_predictions.append(0)\n",
    "    else:\n",
    "        new_predictions.append(1)\n",
    "        \n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print (metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, new_predictions))\n",
    "print (metrics.accuracy_score(test_label, new_predictions),\n",
    "            metrics.precision_score(test_label, new_predictions),\n",
    "            metrics.recall_score(test_label, new_predictions),\n",
    "            metrics.f1_score(test_label, new_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:0.55 Precission:0.62 Recall:0.52 F1:0.56 -> [NB Count]\n",
    "Accuracy:0.51 Precission:0.88 Recall:0.49 F1:0.63 -> [NB TFIDF]\n",
    "Accuracy:0.52 Precission:0.58 Recall:0.49 F1:0.53 -> [NB TFIDF NGram]\n",
    "Accuracy:0.49 Precission:0.96 Recall:0.48 F1:0.64 -> [NB TFIDF NGram Chars]\n",
    "Accuracy:0.55 Precission:0.69 Recall:0.52 F1:0.60 -> [NB LDA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# linear_parameters = {'penalty':('l1', 'l2'), 'C':[10, 1, 0.1, 0.01]}\n",
    "# linear_model = GridSearchCV(LogisticRegression(solver='saga'), scoring = \"f1\",param_grid = linear_parameters, cv=5)\n",
    "\n",
    "# linear_model.fit(train_count, train_label)\n",
    "\n",
    "# predictions = linear_model.predict(test_count)\n",
    "\n",
    "# (metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "\n",
    "# print(linear_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 45]\n",
      " [10 46]]\n",
      "Accuracy:0.50 Precission:0.51 Recall:0.82 F1:0.63 -> [Linear Count]\n",
      "[[42 12]\n",
      " [25 31]]\n",
      "Accuracy:0.66 Precission:0.72 Recall:0.55 F1:0.63 -> [Linear TFIDF]\n",
      "[[36 18]\n",
      " [23 33]]\n",
      "Accuracy:0.63 Precission:0.65 Recall:0.59 F1:0.62 -> [Linear TFIDF NGram]\n",
      "[[21 33]\n",
      " [14 42]]\n",
      "Accuracy:0.57 Precission:0.56 Recall:0.75 F1:0.64 -> [Linear TFIDF NGram Chars]\n",
      "[[42 12]\n",
      " [25 31]]\n",
      "Accuracy:0.66 Precission:0.72 Recall:0.55 F1:0.63 -> [Linear LDA]\n",
      "[[29 25]\n",
      " [31 25]]\n",
      "Accuracy:0.49 Precission:0.50 Recall:0.45 F1:0.47 -> [Linear Doc2Vec]\n"
     ]
    }
   ],
   "source": [
    "linear_config = {\n",
    "    \"Linear Count\": (LogisticRegression(C= 0.1, penalty='l1', tol=0.1, solver='saga'), train_count, test_count)\n",
    "    , \"Linear TFIDF\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), train_tfidf, test_tfidf)\n",
    "    , \"Linear TFIDF NGram\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), train_tfidf_ngram, test_tfidf_ngram)\n",
    "    , \"Linear TFIDF NGram Chars\": (LogisticRegression(C= 0.1, penalty='l2', tol=0.1, solver='saga'), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "#     , \"Linear FastText Embedding\": (LogisticRegression(solver='lbfgs', max_iter=int(1e6)), train_fasttext_embedding, test_fasttext_embedding)\n",
    "    , \"Linear LDA\": (LogisticRegression(solver='lbfgs'), train_lda, test_lda)\n",
    "    , \"Linear Doc2Vec\": (LogisticRegression(solver='lbfgs'), train_doc2vec, test_doc2vec)\n",
    "}\n",
    "\n",
    "# linear_classifiers = {\n",
    "#     \"Linear Count\": (LogisticRegression(), train_count, test_count)\n",
    "#     , \"Linear TFIDF\": (LogisticRegression(), train_tfidf, test_tfidf)\n",
    "#     , \"Linear TFIDF NGram\": (LogisticRegression(), train_tfidf_ngram, test_tfidf_ngram)\n",
    "#     , \"Linear TFIDF NGram Chars\": (LogisticRegression(), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "#     , \"Linear FastText Embedding\": (LogisticRegression(), train_fasttext_embedding, test_fasttext_embedding)\n",
    "#     , \"Linear LDA\": (LogisticRegression(), train_lda, test_lda)\n",
    "#     , \"Linear Doc2Vec\": (LogisticRegression(), train_doc2vec, test_doc2vec)\n",
    "# }\n",
    "\n",
    "run_model(linear_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# svm_parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10, 100], \"gamma\": np.logspace(-2, 2, 5)}\n",
    "# svm_model = GridSearchCV(SVC(), scoring = \"f1\", param_grid = svm_parameters, cv=5)\n",
    "\n",
    "# svm_model.fit(train_tfidf_ngram_chars, train_label)\n",
    "\n",
    "# predictions = svm_model.predict(test_tfidf_ngram_chars)\n",
    "\n",
    "# print(metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "# print(svm_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 52]\n",
      " [ 3 53]]\n",
      "Accuracy:0.50 Precission:0.50 Recall:0.95 F1:0.66 -> [SVM Count]\n",
      "[[46  8]\n",
      " [28 28]]\n",
      "Accuracy:0.67 Precission:0.78 Recall:0.50 F1:0.61 -> [SVM TFIDF]\n",
      "[[34 20]\n",
      " [22 34]]\n",
      "Accuracy:0.62 Precission:0.63 Recall:0.61 F1:0.62 -> [SVM TFIDF NGram]\n",
      "[[13 41]\n",
      " [ 8 48]]\n",
      "Accuracy:0.55 Precission:0.54 Recall:0.86 F1:0.66 -> [SVM TFIDF NGram Chars]\n",
      "[[54  0]\n",
      " [56  0]]\n",
      "Accuracy:0.49 Precission:0.00 Recall:0.00 F1:0.00 -> [SVM LDA]\n",
      "[[15 39]\n",
      " [10 46]]\n",
      "Accuracy:0.55 Precission:0.54 Recall:0.82 F1:0.65 -> [SVM Doc2Vec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dm_cap_py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/dm_cap_py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm_config = {\n",
    "    \"SVM Count\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_count, test_count),\n",
    "    \"SVM TFIDF\": (SVC(C = 10, gamma = 0.01, kernel='rbf'), train_tfidf, test_tfidf),\n",
    "    \"SVM TFIDF NGram\": (SVC(C = 1, gamma = 0.01, kernel='linear'), train_tfidf_ngram, test_tfidf_ngram),\n",
    "    \"SVM TFIDF NGram Chars\": (SVC(C = 10, gamma = 0.01, kernel='rbf'), train_tfidf_ngram_chars, test_tfidf_ngram_chars),\n",
    "#     \"SVM FastText Embedding\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_fasttext_embedding, test_fasttext_embedding),\n",
    "    \"SVM LDA\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_lda, test_lda),\n",
    "    \"SVM Doc2Vec\": (SVC(C = 1, gamma = 0.1, kernel='rbf'), train_doc2vec, test_doc2vec),\n",
    "}\n",
    "    \n",
    "run_model(svm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# xgb_parameters = {\n",
    "#         'min_child_weight': [1, 5, 10],\n",
    "#         'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#         'subsample': [0.6, 0.8, 1.0],\n",
    "#         'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'max_depth': [3, 4, 5]\n",
    "#         }\n",
    "\n",
    "# xgb_model = GridSearchCV(XGBClassifier(), scoring = \"f1\", param_grid = xgb_parameters, cv=5, verbose = 3)\n",
    "\n",
    "# xgb_model.fit(train_count, train_label)\n",
    "\n",
    "# predictions = xgb_model.predict(test_count)\n",
    "\n",
    "# print(metrics.accuracy_score(predictions, test_label),\n",
    "#             metrics.precision_score(predictions, test_label),\n",
    "#             metrics.recall_score(predictions, test_label),\n",
    "#             metrics.f1_score(predictions, test_label))\n",
    "\n",
    "# print(xgb_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37 17]\n",
      " [23 33]]\n",
      "Accuracy:0.64 Precission:0.66 Recall:0.59 F1:0.62 -> [XGBoost Count]\n",
      "[[31 23]\n",
      " [20 36]]\n",
      "Accuracy:0.61 Precission:0.61 Recall:0.64 F1:0.63 -> [XGBoost TFIDF]\n",
      "[[37 17]\n",
      " [30 26]]\n",
      "Accuracy:0.57 Precission:0.60 Recall:0.46 F1:0.53 -> [XGBoost TFIDF NGram]\n",
      "[[24 30]\n",
      " [24 32]]\n",
      "Accuracy:0.51 Precission:0.52 Recall:0.57 F1:0.54 -> [XGBoost TFIDF NGram Chars]\n",
      "[[40 14]\n",
      " [28 28]]\n",
      "Accuracy:0.62 Precission:0.67 Recall:0.50 F1:0.57 -> [XGBoost LDA]\n",
      "[[33 21]\n",
      " [26 30]]\n",
      "Accuracy:0.57 Precission:0.59 Recall:0.54 F1:0.56 -> [XGBoost Doc2Vec]\n"
     ]
    }
   ],
   "source": [
    "# xgboost_config = {\n",
    "#     \"XGBoost Count\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_count, test_count)\n",
    "#     , \"XGBoost TFIDF\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_tfidf, test_tfidf)\n",
    "#     , \"XGBoost TFIDF NGram\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_tfidf_ngram.tocsc(), test_tfidf_ngram.tocsc())\n",
    "#     , \"XGBoost TFIDF NGram Chars\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "#     , \"XGBoost LDA\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_lda, test_lda)\n",
    "#     , \"XGBoost Doc2Vec\": (XGBClassifier(colsample_bytree = 0.8, gamma= 2, max_depth = 4, min_child_weight = 1, subsample =1.0), train_doc2vec, test_doc2vec)\n",
    "# }\n",
    "\n",
    "xgboost_config = {\n",
    "    \"XGBoost Count\": (XGBClassifier(), train_count, test_count)\n",
    "    , \"XGBoost TFIDF\": (XGBClassifier(), train_tfidf, test_tfidf)\n",
    "    , \"XGBoost TFIDF NGram\": (XGBClassifier(), train_tfidf_ngram.tocsc(), test_tfidf_ngram.tocsc())\n",
    "    , \"XGBoost TFIDF NGram Chars\": (XGBClassifier(), train_tfidf_ngram_chars, test_tfidf_ngram_chars)\n",
    "    , \"XGBoost LDA\": (XGBClassifier(), train_lda, test_lda)\n",
    "    , \"XGBoost Doc2Vec\": (XGBClassifier(), train_doc2vec, test_doc2vec)\n",
    "}\n",
    "\n",
    "run_model(xgboost_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 51]\n",
      " [ 5 51]]\n",
      "0.4909090909090909 0.5 0.9107142857142857 0.6455696202531646\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "_dictionary = corpora.Dictionary(train_stemmed_text)\n",
    "train_doc_count = [_dictionary.doc2bow(_doc) for _doc in train_stemmed_text]\n",
    "test_doc_count = [_dictionary.doc2bow(_doc) for _doc in test_stemmed_text]\n",
    "\n",
    "tfidf_model = models.TfidfModel(train_doc_count)\n",
    "train_doc_tfidf = [dict(_doc) for _doc in tfidf_model[train_doc_count]]\n",
    "train_doc_tfidf = [(_doc, train_label[train_label.index[i]]) for i, _doc in enumerate(train_doc_tfidf)]\n",
    "test_doc_tfidf = [dict(_doc) for _doc in tfidf_model[test_doc_count]]\n",
    "\n",
    "train_doc_count = [(dict(_doc), train_label[train_label.index[i]]) for i, _doc in enumerate(train_doc_count)]\n",
    "test_doc_count = [dict(_doc) for _doc in test_doc_count]\n",
    "\n",
    "NB_classifier_count = NaiveBayesClassifier.train(train_doc_count)\n",
    "\n",
    "predictions = NB_classifier_count.classify_many(test_doc_count)\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print(metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 54]\n",
      " [ 0 56]]\n",
      "0.509090909090909 0.509090909090909 1.0 0.6746987951807228\n"
     ]
    }
   ],
   "source": [
    "NB_classifier_tfidf = NaiveBayesClassifier.train(train_doc_tfidf)\n",
    "predictions = NB_classifier_tfidf.classify_many(test_doc_tfidf)\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print(metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0]\n",
      " [56  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geesi\\Anaconda3\\envs\\dm_cap_mkl_py3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\geesi\\Anaconda3\\envs\\dm_cap_mkl_py3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4909090909090909 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "DT_classifier_count = DecisionTreeClassifier.train(train_doc_tfidf)\n",
    "predictions = DT_classifier_count.classify_many(test_doc_tfidf)\n",
    "\n",
    "print(metrics.confusion_matrix(test_label, predictions))\n",
    "print(metrics.accuracy_score(test_label, predictions),\n",
    "            metrics.precision_score(test_label, predictions),\n",
    "            metrics.recall_score(test_label, predictions),\n",
    "            metrics.f1_score(test_label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
